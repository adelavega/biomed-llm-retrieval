{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec33aee1-7c7b-4e3a-8b81-b1bd79e1ca5f",
   "metadata": {},
   "source": [
    "# Full Text Search evaluation with participant demographics\n",
    "\n",
    "Here, I evaluate the strategy of finding relevant text sections using chunk embeddings.\n",
    "\n",
    "First, I split PMC articles using Markdown (and lines), into chunks less than `n_tokens` (~4000).\n",
    "\n",
    "Next, we embed each chunks.\n",
    "\n",
    "Finally, using a text query, we find the most relevant section of each article for finding participant demographics.\n",
    "The query is also embedded and a distance metric is taken between each chunk and the query.\n",
    "\n",
    "To evaluate this method, I will see if this method correctly identifies the section where human annotators found demographic info."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7250c22c-a887-48b7-9e1d-73071984059f",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31043f58-23b0-4ad8-a3db-5b6875442ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from labelrepo.projects.participant_demographics import get_participant_demographics\n",
    "from labelrepo.database import get_database_connection\n",
    "\n",
    "subgroups = get_participant_demographics(include_locations=True)\n",
    "docs_info = pd.read_sql(\n",
    "    \"select pmcid, publication_year, title, text from document\",\n",
    "    get_database_connection(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "074e1132-e726-41c9-bbd2-dbbf9c4ba2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only look at single group documents\n",
    "jerome_pd = subgroups[(subgroups.project_name == 'participant_demographics') & \\\n",
    "                      (subgroups.annotator_name == 'Jerome_Dockes')]\n",
    "\n",
    "counts = jerome_pd.groupby('pmcid').count().reset_index()\n",
    "single_group_pmcids = counts[counts['count'] == 1].pmcid\n",
    "single_group = jerome_pd[jerome_pd.pmcid.isin(single_group_pmcids)]\n",
    "single_group_docs = docs_info[docs_info.pmcid.isin(single_group.pmcid)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd675144-aceb-45be-8844-96a3e6ed573a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from split import split_pmc_document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5aca89c4-054a-44f3-bd92-b74c31dab242",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>start_chars</th>\n",
       "      <th>end_chars</th>\n",
       "      <th>section_0</th>\n",
       "      <th>section_1</th>\n",
       "      <th>section_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pulli, Elmo P. and Silver, Eero and Kumpulaine...</td>\n",
       "      <td>0</td>\n",
       "      <td>323</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n# Title\\n\\nFeasibility of FreeSurfer Process...</td>\n",
       "      <td>323</td>\n",
       "      <td>468</td>\n",
       "      <td>Title</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n# Keywords\\n\\nbrain\\nchild\\nneuroimaging\\nbr...</td>\n",
       "      <td>468</td>\n",
       "      <td>563</td>\n",
       "      <td>Keywords</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\n# Abstract\\n \\nPediatric neuroimaging is a q...</td>\n",
       "      <td>563</td>\n",
       "      <td>2381</td>\n",
       "      <td>Abstract</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\n# Body\\n \\n## Introduction \\n  \\nThere are m...</td>\n",
       "      <td>2381</td>\n",
       "      <td>5253</td>\n",
       "      <td>Body</td>\n",
       "      <td>Introduction</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\\nQuality control is often done by applying a ...</td>\n",
       "      <td>5253</td>\n",
       "      <td>9234</td>\n",
       "      <td>Body</td>\n",
       "      <td>Introduction</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\\n## Materials and Methods \\n  \\nThis study wa...</td>\n",
       "      <td>9234</td>\n",
       "      <td>9500</td>\n",
       "      <td>Body</td>\n",
       "      <td>Materials and Methods</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\\n### Participants \\n  \\nThe participants are ...</td>\n",
       "      <td>9500</td>\n",
       "      <td>12550</td>\n",
       "      <td>Body</td>\n",
       "      <td>Materials and Methods</td>\n",
       "      <td>Participants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\\n### The Study Visits \\n  \\nAll MRI scans wer...</td>\n",
       "      <td>12550</td>\n",
       "      <td>16313</td>\n",
       "      <td>Body</td>\n",
       "      <td>Materials and Methods</td>\n",
       "      <td>The Study Visits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\\nAll images were viewed by one neuroradiologi...</td>\n",
       "      <td>16313</td>\n",
       "      <td>16826</td>\n",
       "      <td>Body</td>\n",
       "      <td>Materials and Methods</td>\n",
       "      <td>The Study Visits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>\\n### Magnetic Resonance Imaging Data Acquisit...</td>\n",
       "      <td>16826</td>\n",
       "      <td>17958</td>\n",
       "      <td>Body</td>\n",
       "      <td>Materials and Methods</td>\n",
       "      <td>Magnetic Resonance Imaging Data Acquisition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>\\n### Data Processing \\n  \\n#### FreeSurfer \\n...</td>\n",
       "      <td>17958</td>\n",
       "      <td>21851</td>\n",
       "      <td>Body</td>\n",
       "      <td>Materials and Methods</td>\n",
       "      <td>Data Processing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>\\nA presentation of some common errors and fix...</td>\n",
       "      <td>21851</td>\n",
       "      <td>25716</td>\n",
       "      <td>Body</td>\n",
       "      <td>Materials and Methods</td>\n",
       "      <td>Data Processing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>\\nFurthermore, there are some error types that...</td>\n",
       "      <td>25716</td>\n",
       "      <td>29251</td>\n",
       "      <td>Body</td>\n",
       "      <td>Materials and Methods</td>\n",
       "      <td>Data Processing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>\\nAfter the quality control that entailed manu...</td>\n",
       "      <td>29251</td>\n",
       "      <td>33062</td>\n",
       "      <td>Body</td>\n",
       "      <td>Materials and Methods</td>\n",
       "      <td>Data Processing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>\\nCases of superior parietal overestimation we...</td>\n",
       "      <td>33062</td>\n",
       "      <td>37008</td>\n",
       "      <td>Body</td>\n",
       "      <td>Materials and Methods</td>\n",
       "      <td>Data Processing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>\\nWe performed the full ENIGMA quality control...</td>\n",
       "      <td>37008</td>\n",
       "      <td>39737</td>\n",
       "      <td>Body</td>\n",
       "      <td>Materials and Methods</td>\n",
       "      <td>Data Processing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>\\n### Alternate Quality Control: Qoala-T \\n  \\...</td>\n",
       "      <td>39737</td>\n",
       "      <td>40132</td>\n",
       "      <td>Body</td>\n",
       "      <td>Materials and Methods</td>\n",
       "      <td>Alternate Quality Control: Qoala-T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>\\n### Statistics \\n  \\nStatistical analyses we...</td>\n",
       "      <td>40132</td>\n",
       "      <td>43938</td>\n",
       "      <td>Body</td>\n",
       "      <td>Materials and Methods</td>\n",
       "      <td>Statistics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>\\nAll significances were calculated 2-tailed (...</td>\n",
       "      <td>43938</td>\n",
       "      <td>44368</td>\n",
       "      <td>Body</td>\n",
       "      <td>Materials and Methods</td>\n",
       "      <td>Statistics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>\\n## Results \\n  \\n### Demographics \\n  \\nTher...</td>\n",
       "      <td>44368</td>\n",
       "      <td>45820</td>\n",
       "      <td>Body</td>\n",
       "      <td>Results</td>\n",
       "      <td>Demographics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>\\n### Comparison Between Unedited and Manually...</td>\n",
       "      <td>45820</td>\n",
       "      <td>49523</td>\n",
       "      <td>Body</td>\n",
       "      <td>Results</td>\n",
       "      <td>Comparison Between Unedited and Manually Edite...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>\\nThe mean change in absolute volume values be...</td>\n",
       "      <td>49523</td>\n",
       "      <td>50153</td>\n",
       "      <td>Body</td>\n",
       "      <td>Results</td>\n",
       "      <td>Comparison Between Unedited and Manually Edite...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>\\n### The ENIGMA and Freeview Quality Control ...</td>\n",
       "      <td>50153</td>\n",
       "      <td>51410</td>\n",
       "      <td>Body</td>\n",
       "      <td>Results</td>\n",
       "      <td>The ENIGMA and Freeview Quality Control Protoc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>\\n### ENIGMA Exclusion Differences Between Edi...</td>\n",
       "      <td>51410</td>\n",
       "      <td>52721</td>\n",
       "      <td>Body</td>\n",
       "      <td>Results</td>\n",
       "      <td>ENIGMA Exclusion Differences Between Edited an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>\\n### Sex Differences \\n  \\nMore extensive res...</td>\n",
       "      <td>52721</td>\n",
       "      <td>54810</td>\n",
       "      <td>Body</td>\n",
       "      <td>Results</td>\n",
       "      <td>Sex Differences</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>\\n### Structural Asymmetry \\n  \\nMore extensiv...</td>\n",
       "      <td>54810</td>\n",
       "      <td>56735</td>\n",
       "      <td>Body</td>\n",
       "      <td>Results</td>\n",
       "      <td>Structural Asymmetry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>\\n## Discussion \\n  \\nIn this article, we desc...</td>\n",
       "      <td>56735</td>\n",
       "      <td>60725</td>\n",
       "      <td>Body</td>\n",
       "      <td>Discussion</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>\\nThe manual editing procedures in many of the...</td>\n",
       "      <td>60725</td>\n",
       "      <td>63963</td>\n",
       "      <td>Body</td>\n",
       "      <td>Discussion</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>\\nWe also examined the effects of our manual e...</td>\n",
       "      <td>63963</td>\n",
       "      <td>67847</td>\n",
       "      <td>Body</td>\n",
       "      <td>Discussion</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>\\nIn contrast, in the macro scale assessment, ...</td>\n",
       "      <td>67847</td>\n",
       "      <td>71377</td>\n",
       "      <td>Body</td>\n",
       "      <td>Discussion</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>\\nThe key practical benefit in our manual edit...</td>\n",
       "      <td>71377</td>\n",
       "      <td>73845</td>\n",
       "      <td>Body</td>\n",
       "      <td>Discussion</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>\\nCertain typical errors can appear in unedite...</td>\n",
       "      <td>73845</td>\n",
       "      <td>77755</td>\n",
       "      <td>Body</td>\n",
       "      <td>Discussion</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>\\n## Conclusion \\n  \\nThere is no single “gold...</td>\n",
       "      <td>77755</td>\n",
       "      <td>78819</td>\n",
       "      <td>Body</td>\n",
       "      <td>Conclusion</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>\\n## Data Availability Statement \\n  \\nThe dat...</td>\n",
       "      <td>78819</td>\n",
       "      <td>79223</td>\n",
       "      <td>Body</td>\n",
       "      <td>Data Availability Statement</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>\\n## Ethics Statement \\n  \\nThe studies involv...</td>\n",
       "      <td>79223</td>\n",
       "      <td>79535</td>\n",
       "      <td>Body</td>\n",
       "      <td>Ethics Statement</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>\\n## Author Contributions \\n  \\nEP, ESi, and J...</td>\n",
       "      <td>79535</td>\n",
       "      <td>79985</td>\n",
       "      <td>Body</td>\n",
       "      <td>Author Contributions</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>\\n## Conflict of Interest \\n  \\nThe authors de...</td>\n",
       "      <td>79985</td>\n",
       "      <td>80189</td>\n",
       "      <td>Body</td>\n",
       "      <td>Conflict of Interest</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>\\n## Publisher’s Note \\n  \\nAll claims express...</td>\n",
       "      <td>80189</td>\n",
       "      <td>80565</td>\n",
       "      <td>Body</td>\n",
       "      <td>Publisher’s Note</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              content  start_chars  end_chars  \\\n",
       "0   Pulli, Elmo P. and Silver, Eero and Kumpulaine...            0        323   \n",
       "1   \\n# Title\\n\\nFeasibility of FreeSurfer Process...          323        468   \n",
       "2   \\n# Keywords\\n\\nbrain\\nchild\\nneuroimaging\\nbr...          468        563   \n",
       "3   \\n# Abstract\\n \\nPediatric neuroimaging is a q...          563       2381   \n",
       "4   \\n# Body\\n \\n## Introduction \\n  \\nThere are m...         2381       5253   \n",
       "5   \\nQuality control is often done by applying a ...         5253       9234   \n",
       "6   \\n## Materials and Methods \\n  \\nThis study wa...         9234       9500   \n",
       "7   \\n### Participants \\n  \\nThe participants are ...         9500      12550   \n",
       "8   \\n### The Study Visits \\n  \\nAll MRI scans wer...        12550      16313   \n",
       "9   \\nAll images were viewed by one neuroradiologi...        16313      16826   \n",
       "10  \\n### Magnetic Resonance Imaging Data Acquisit...        16826      17958   \n",
       "11  \\n### Data Processing \\n  \\n#### FreeSurfer \\n...        17958      21851   \n",
       "12  \\nA presentation of some common errors and fix...        21851      25716   \n",
       "13  \\nFurthermore, there are some error types that...        25716      29251   \n",
       "14  \\nAfter the quality control that entailed manu...        29251      33062   \n",
       "15  \\nCases of superior parietal overestimation we...        33062      37008   \n",
       "16  \\nWe performed the full ENIGMA quality control...        37008      39737   \n",
       "17  \\n### Alternate Quality Control: Qoala-T \\n  \\...        39737      40132   \n",
       "18  \\n### Statistics \\n  \\nStatistical analyses we...        40132      43938   \n",
       "19  \\nAll significances were calculated 2-tailed (...        43938      44368   \n",
       "20  \\n## Results \\n  \\n### Demographics \\n  \\nTher...        44368      45820   \n",
       "21  \\n### Comparison Between Unedited and Manually...        45820      49523   \n",
       "22  \\nThe mean change in absolute volume values be...        49523      50153   \n",
       "23  \\n### The ENIGMA and Freeview Quality Control ...        50153      51410   \n",
       "24  \\n### ENIGMA Exclusion Differences Between Edi...        51410      52721   \n",
       "25  \\n### Sex Differences \\n  \\nMore extensive res...        52721      54810   \n",
       "26  \\n### Structural Asymmetry \\n  \\nMore extensiv...        54810      56735   \n",
       "27  \\n## Discussion \\n  \\nIn this article, we desc...        56735      60725   \n",
       "28  \\nThe manual editing procedures in many of the...        60725      63963   \n",
       "29  \\nWe also examined the effects of our manual e...        63963      67847   \n",
       "30  \\nIn contrast, in the macro scale assessment, ...        67847      71377   \n",
       "31  \\nThe key practical benefit in our manual edit...        71377      73845   \n",
       "32  \\nCertain typical errors can appear in unedite...        73845      77755   \n",
       "33  \\n## Conclusion \\n  \\nThere is no single “gold...        77755      78819   \n",
       "34  \\n## Data Availability Statement \\n  \\nThe dat...        78819      79223   \n",
       "35  \\n## Ethics Statement \\n  \\nThe studies involv...        79223      79535   \n",
       "36  \\n## Author Contributions \\n  \\nEP, ESi, and J...        79535      79985   \n",
       "37  \\n## Conflict of Interest \\n  \\nThe authors de...        79985      80189   \n",
       "38  \\n## Publisher’s Note \\n  \\nAll claims express...        80189      80565   \n",
       "\n",
       "   section_0                     section_1  \\\n",
       "0        NaN                           NaN   \n",
       "1      Title                           NaN   \n",
       "2   Keywords                           NaN   \n",
       "3   Abstract                           NaN   \n",
       "4       Body                 Introduction    \n",
       "5       Body                 Introduction    \n",
       "6       Body        Materials and Methods    \n",
       "7       Body        Materials and Methods    \n",
       "8       Body        Materials and Methods    \n",
       "9       Body        Materials and Methods    \n",
       "10      Body        Materials and Methods    \n",
       "11      Body        Materials and Methods    \n",
       "12      Body        Materials and Methods    \n",
       "13      Body        Materials and Methods    \n",
       "14      Body        Materials and Methods    \n",
       "15      Body        Materials and Methods    \n",
       "16      Body        Materials and Methods    \n",
       "17      Body        Materials and Methods    \n",
       "18      Body        Materials and Methods    \n",
       "19      Body        Materials and Methods    \n",
       "20      Body                      Results    \n",
       "21      Body                      Results    \n",
       "22      Body                      Results    \n",
       "23      Body                      Results    \n",
       "24      Body                      Results    \n",
       "25      Body                      Results    \n",
       "26      Body                      Results    \n",
       "27      Body                   Discussion    \n",
       "28      Body                   Discussion    \n",
       "29      Body                   Discussion    \n",
       "30      Body                   Discussion    \n",
       "31      Body                   Discussion    \n",
       "32      Body                   Discussion    \n",
       "33      Body                   Conclusion    \n",
       "34      Body  Data Availability Statement    \n",
       "35      Body             Ethics Statement    \n",
       "36      Body         Author Contributions    \n",
       "37      Body         Conflict of Interest    \n",
       "38      Body             Publisher’s Note    \n",
       "\n",
       "                                            section_2  \n",
       "0                                                 NaN  \n",
       "1                                                 NaN  \n",
       "2                                                 NaN  \n",
       "3                                                 NaN  \n",
       "4                                                None  \n",
       "5                                                None  \n",
       "6                                                 NaN  \n",
       "7                                       Participants   \n",
       "8                                   The Study Visits   \n",
       "9                                   The Study Visits   \n",
       "10       Magnetic Resonance Imaging Data Acquisition   \n",
       "11                                   Data Processing   \n",
       "12                                   Data Processing   \n",
       "13                                   Data Processing   \n",
       "14                                   Data Processing   \n",
       "15                                   Data Processing   \n",
       "16                                   Data Processing   \n",
       "17                Alternate Quality Control: Qoala-T   \n",
       "18                                        Statistics   \n",
       "19                                        Statistics   \n",
       "20                                      Demographics   \n",
       "21  Comparison Between Unedited and Manually Edite...  \n",
       "22  Comparison Between Unedited and Manually Edite...  \n",
       "23  The ENIGMA and Freeview Quality Control Protoc...  \n",
       "24  ENIGMA Exclusion Differences Between Edited an...  \n",
       "25                                   Sex Differences   \n",
       "26                              Structural Asymmetry   \n",
       "27                                               None  \n",
       "28                                               None  \n",
       "29                                               None  \n",
       "30                                               None  \n",
       "31                                               None  \n",
       "32                                               None  \n",
       "33                                                NaN  \n",
       "34                                                NaN  \n",
       "35                                                NaN  \n",
       "36                                                NaN  \n",
       "37                                                NaN  \n",
       "38                                                NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(split_pmc_document(single_group_docs.iloc[0].text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc0f167-e798-4454-82ac-6fc869ff4ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/home/zorro/repos/biomed-llm-retrieval/split.py\u001b[0m(68)\u001b[0;36msplit_markdown\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     66 \u001b[0;31m        \u001b[0;32mif\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     67 \u001b[0;31m            \u001b[0;32mif\u001b[0m \u001b[0;34m'Materials and Methods'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 68 \u001b[0;31m                \u001b[0;32massert\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     69 \u001b[0;31m            \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mix\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     70 \u001b[0;31m                \u001b[0msection_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcandidate_chunks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxsplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  chunk\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Materials and Methods \\n  \\nThis study was conducted in accordance with the Declaration of Helsinki, and it was approved by the Joint Ethics Committee of the University of Turku and the Hospital District of Southwest Finland (07.08.2018) §330, ETMK: 31/180/2011. \\n\\n### Participants \\n  \\nThe participants are part of the FinnBrain Birth Cohort Study  ( ), where 5-year-olds were invited to neuropsychological, logopedic, neuroimaging, and pediatric study visits. For the neuroimaging visit, we primarily recruited participants that had a prior visit to neuropsychological measurements at circa 5 years of age (  n   = 141/146). However, there were a few exceptions: three participants were included without a neuropsychological visit, as they had an exposure to maternal prenatal synthetic glucocorticoid treatment (recruited separately for a nested case–control sub-study). The data additionally includes two participants that were enrolled for pilot scans. We aimed to scan all subjects between the ages 5 years 3 months and 5 years 5 months, and 135/146 (92%) of the participants attended the visit within this timeframe (reasons to scan outside the timeframe include, for example, the family moving the visit to a later date). The exclusion criteria for this study were: (1) born before gestational week 35 (before gestational week 32 for those with exposure to maternal prenatal synthetic glucocorticoid treatment), (2) developmental anomaly or abnormalities in senses or communication (e.g., blindness, deafness, and congenital heart disease), (3) known long-term medical diagnosis (e.g., epilepsy and autism), (4) ongoing medical examinations or clinical follow up in a hospital (meaning there has been a referral from primary care setting to special health care), (5) child use of continuous, daily medication (including per oral medications, topical creams, and inhalants. One exception to this was desmopressin ( Minirin) medication, which was allowed), (6) history of head trauma (defined as concussion necessitating clinical follow up in a health care setting or worse), (7) metallic (golden) ear tubes (to assure good-quality scans), and routine MRI contraindications. \\n\\nIn the current study, we used a subsample (approximately two thirds of the full sample) that consists of the participants that were scanned before a temporary stop to visits due to the restrictions caused by the coronavirus disease 2019 (COVID-19) pandemic. The scans were performed between 29 October, 2017 and 1 March, 2020. We contacted 415 families and reached 363 (87%) of them. In total, 146 (40% of the reached families) participants attended imaging visits (one pair of twins, one participant attended twice, and only the latter scan was included). Eight of them did not start the scan, and four were excluded due to excess motion artifact in the T1-image. Thereafter, 134 T1 images (mean age 5.34 years, SD 0.06 years, range 5.08–5.22 years, 72 boys, 62 girls) entered the processing pipelines.   presents the demographic data as recommended in our earlier review ( ). A flowchart depicting the formation of the final sample through the different exclusion steps is presented in  . \\n  \\nA flowchart depicting the steps leading to our final sample size of 121. The region of interest (ROI) exclusions are presented in  . \\n  \\n\\n### The Study Visits \\n  \\nAll MRI scans were performed for research purposes by the research staff (one research nurse, four Ph.D. students, and two MR technologists). Before the visit, each family was personally contacted and recruited via telephone calls by a research staff member. The scan preparations started with the recruitment and at home training. We introduced the image acquisition process to the parents and advised them to explain the process to their children and confirm child assent before the follow up phone call that was used to confirm the willingness to participate. Thereafter, we advised the parents to use at home familiarization methods such as showing a video describing the visit, playing audio of scanner sounds, encouraging the child to lie still like a statue (“statue game”), and practicing with a homemade mock scanner, e.g., a cardboard box with a hole to view a movie through. The visit was marketed to the participants as a “space adventure,” which is in principle similar to the previously described “submarine protocol” ( ) but the child was allowed to come up with other settings as well. A member of the research staff made a home visit before the scan to deliver earplugs and headphones, to give more detailed information about the visit, and to answer any remaining questions. An added benefit of the home visit was the chance to meet the participating child and that way start the familiarization with the research staff. \\n\\nAt the start of the visit, we familiarized the participant with the research team (research nurse and a medically trained Ph.D. student) and acquired written informed consent from both parents. This first portion of the visit included a practice session using a non-commercial mock scanner consisting of a toy tunnel and a homemade wooden head coil. Inexpensive non-commercial mock scanners have been shown to be as effective as commercial ones ( ). The participants brought at least one of their toys that would undergo a mock scan (e.g., an MRI compatible stuffed animal they could also bring with them into the real scanner). The researcher played scanner sounds on their cell phone during the mock scan and the child could take pictures of the toy lying still and of the toy being moved by the researcher to demonstrate the importance of lying still during the scan. Communication during the scan was practiced. Overall, these preparations at the scan site were highly variable as we did our best to accommodate to befit the child characteristics (e.g., taking into account the physical activity and anxiety) in cooperation with the family. Finally, we served a light meal of the participant’s choice before the scan. \\n\\nThe participants were scanned awake or during natural sleep. One member of the research staff and parent(s) stayed in the scanner room throughout the whole scan. During the scan, participants wore earplugs and headphones. Through the headphones, they were able to listen to the movie or TV show of their choice while watching it with the help of mirrors fitted into the head coil (the TV was located at the foot of the bed of the scanner). Some foam padding was applied to help the head stay still and assure comfortable position. Participants were given a “signal ball” to throw in case they needed or wanted to stop or pause the scan (e.g., to visit the toilet). If the research staff member noticed movement, they gently reminded the participant to stay still by lightly touching their foot. This method of communication was agreed on earlier in the visit and was planned to convey a clear signal of presence while minimizing the tactile stimulation. Many of the methods used to reduce anxiety and motion during the scan have been described in earlier studies ( ;  ). \\n\\nAll images were viewed by one neuroradiologist (RP) who then consulted a pediatric neurologist (TL) when necessary. There were four (out of 146, 2.7%) cases with an incidental finding that required consultation. All four cases initially entered the FreeSurfer processing pipeline and three were included in the final ROI based analyses. The protocol with incidental findings has been described in our earlier work ( ), and a separate report of their incidence is in preparation for the eventual full data set. \\n\\n\\n### Magnetic Resonance Imaging Data Acquisition \\n  \\nParticipants were scanned using a Siemens Magnetom Skyra fit 3T with a 20-element head/neck matrix coil. We used Generalized Autocalibrating Partially Parallel Acquisition (GRAPPA) technique to accelerate image acquisition [parallel acquisition technique (PAT) factor of 2 was used]. The MRI data was acquired as a part of max. 60-min scan protocol. The scans included a high resolution T1 magnetization prepared rapid gradient echo (MPRAGE), a T2 turbo spin echo (TSE), a 7-min resting state functional MRI, and a 96-direction single shell (b = 1,000 s/mm ) diffusion tensor imaging (DTI) sequence ( ) as well as a 31-direction with b = 650 s/mm  and a 80-direction with b = 2,000 s/mm . For the purposes of the current study, we acquired high resolution T1-weighted images with the following sequence parameters: repetition time (TR) = 1,900 ms, echo time (TE) = 3.26 ms, inversion time (TI) = 900 ms, flip angle = 9 degrees, voxel size = 1.0 × 1.0 × 1.0 mm , and field of view (FOV) 256 × 256 mm . The scans were planned as per recommendations of the FreeSurfer developers. \\n\\n\\n### Data Processing \\n  \\n#### FreeSurfer \\n  \\nCortical reconstruction and volumetric segmentation for all 134 images were performed with the FreeSurfer software suite, version 6.0.0.  We selected the T1 image with the least motion artifact (in case there were several attempts due to visible motion during scan) and then applied the “recon-all” processing stream with default parameters. It begins with transformation to Talaraich space, intensity inhomogeneity correction, bias field correction ( ), and skull-stripping ( ). Thereafter, WM is separated from GM and other tissues and the volume within the created WM–GM boundary is filled. After this, the surface is tessellated and smoothed. After these preprocessing steps are completed, the surface is inflated ( ) and registered to a spherical atlas. This method adapts to the folding pattern of each individual brain, utilizing consistent folding patterns such as the central sulcus and the sylvian fissure as landmarks, allowing for high localization accuracy ( ). FreeSurfer uses probabilistic approach based on Markov random fields for automated labeling of brain regions. Cortical thickness is calculated as the average distance between the WM–GM boundary and the pial surface on the tessellated surface ( ). The cortical thickness measurement technique has been validated against post-mortem histological ( ) and manual measurements ( ;  ). \\n\\n\\n#### FreeSurfer Manual Edits and the Freeview Quality Control Protocol \\n  \\nWe used Freeview to view and edit the images using the standard command recommended by the FreeSurfer instructions with the addition of the Desikan–Killiany atlas that allowed us to correctly identify the ROIs where errors were found. Images with excess motion artifact or large unsegmented regions (extending over multiple gyri, examples provided in  ) were excluded. There were 13 participants that were excluded due to erroneous segmentation. The images that passed the initial quality check were then manually edited (the time required for manual editing ranged from 45 min in high quality images to over 3 h in images with a lot of artifact, taking approximately 2 h on average). All images were examined in all three directions one hemisphere at a time and the edits were made for every slice regardless of the ROI in question. Subsequently, we ran the automated segmentation process again as suggested by FreeSurfer instructions. The images were then inspected again for errors, and the ROIs with errors that affect WM–GM or pial borders were excluded in the Freeview quality control protocol. The Freeview protocol presented in this study was adapted locally for the FinnBrain Neuroimaging Lab as a method to assess errors in a slice-by-slice view from the official quality control procedure provided in the FreeSurfer instructions.  We also provide a practical application manual in   ( , pages 3–9, FreeSurfer editing) that we give to new researchers when they start practicing the FinnBrain manual editing and quality control protocol. \\n\\n##### Errors in Borders \\n  \\nThe automatically segmented images generated by FreeSurfer software suite were visually inspected and the found errors were either manually corrected or the ROI with the error was simply excluded depending on the type of error. Excess parts of the skull were removed where the pial border was affected by them ( ). Arteries were removed to avoid segmentation errors between arteries and WM (especially relevant for anterior temporal areas and the insulae). This was done by setting the eraser to only delete voxels with intensity between 130 and 190 in the brainmask volume. The arteries were removed throughout the image with no regard to whether they caused issues in the segmentation on that specific slice. An example can be seen in  . In cases where an error appeared in a junction between ROIs, all adjoining ROIs were excluded. \\n  \\nA presentation of some common errors and fixes related to the pial border and non-brain tissues.   (A)   Demonstrates how skull fragments can cause errors in pial border (yellow circles).   (B)   Presents the same subject with skull fragments removed. In panel   (C)  , arteries were removed (green circle). We removed voxels with an intensity between 130 and 190, and therefore some parts of arteries were not removed (yellow circle).   (C)   Also demonstrates the challenges with artifact, meninges, and the pial border. In some areas, the pial border may extend into the meninges (yellow arrows). Meanwhile, at the other end of the same gyrus, the border may seem correct (green arrows). It is difficult to fix these errors manually. Additionally, the visible motion artifact adds further challenges to manual edits of the pial border. In panel   (D)  , the pial border cuts through a gyrus. \\n  \\nOne typical error was that parts of the superior sagittal sinus (SSS) were included within the pial border. We stopped editing the SSS after an interim assessment as it was an arduous task with little effect on final results. All information regarding SSS edits is presented in   ( , pages 10–14, Superior sagittal sinus). \\n\\nIn addition, there were errors that could not be fixed easily. In some cases, the pial border may cut through the cortex (  shows an error in the left rostral middle frontal region). In these cases, the remaining GM mask is too small, and this error cannot be easily fixed in Freeview. Manual segmentation of a T1 image is labor intensive and hard to conduct reliably with 1 mm  resolution even when the edits would cover small areas. Moreover, the FreeSurfer instructions do not recommend this approach. Additionally, the WM mask edits recommended in FreeSurfer instructions would not fix all cases where the cortical segmentation is too thin, as the WM mask often seemed adequate in these areas (an example presented in  ). Therefore, we simply had to exclude the ROI(s) in question. \\n\\nSmall errors of the WM–GM border were prevalent throughout the brain. The corrections were made by erasing excess WM mask. This process is demonstrated in  . WM–GM border was inspected after the manual edits. A continuous error of at least ten slices in the coronal view led to exclusion of all the ROIs directly impacted by the error. Furthermore, ubiquitous errors in the WM–GM border, as markers of motion artifact, led to exclusion of the whole brain (as in  ). \\n  \\nA demonstration of our white matter (WM) mask editing protocol.   (A)   Shows a typical error in the border between white and gray matter (WM–GM border), where it extends too close to the pial border. Errors such as this are searched for in the “brainmask” volume   (A,D)  .   (B)   Shows the same error in “wm” volume with “Jet” colormap   (B,C)  .   (C)   Shows how we fixed these errors by erasing the erroneous WM mask (blue voxels).   (D)   Shows the final result after the second recon-all. \\n    \\nTwo examples of excluded brain images.   (A)   Shows “waves” throughout the image, marking motion artifact.   (B)   Shows the same subject as in panel   (A)   in a coronal view and borders visible. This image shows motion artifact related errors in the border between white and gray matter (WM–GM border), denoted by the yellow circle. Additionally, there is potential unsegmented area due to motion artifact (green circle) and poor contrast between WM and GM (white circle).   (C,D)   Show another excluded subject. The motion artifact in panel   (C)   is not as pronounced as in panel   (A)  . However,   (D)   still shows some typical errors for images with much artifact. There is a clear pial error (white arrow). Additionally, the yellow arrows show typical cases, where the “ringing” causes the WM mask to “widen” where the actual WM meets the ringing motion artifact. \\n  \\nFurthermore, there are some error types that cannot be easily fixed but also do not warrant exclusion. One such problem is that the pial border often extends into the cerebrospinal fluid or meninges around the brain ( ). The issue with this type of error is that sometimes the real border between GM and the surrounding meninges cannot be denoted visually and therefore the error cannot be reliably fixed. This problem is further complicated by the fact that motion artifact may mimic the border between GM and meninges making the visual quality control challenging (  and  ). In addition to motion, fat shift can also cause this type of artifact. The amount of fat shift in images is dependent on the imaging protocol, more specifically the bandwidth of the acquisition. \\n\\nThere were some minor incongruities in multiple images. A common example can be seen in  , where there seems to be a potential error in the pial border. Areas like this look normal in other planes. A less common example is shown in  , where there is an apparent discontinuation in the WM–GM border. Similarly, there was no discontinuation in other planes. Both these minor incongruities were considered partial volume effects related to the presentation of a 3D surface in 2D slices. Therefore, both cases were included. \\n\\n\\n##### Errors in Cortical Labeling \\n  \\nA common issue was the presence of WM hypointensities in the segmented images. They sometimes erroneously appeared in the cortex. These errors were typically small and did not cause errors in pial or WM–GM borders ( ), and in those cases did not require exclusion. The hypointensities themselves were rarely successfully fixed by editing the WM mask and therefore were left unedited unless they caused errors in the GM–WM border. In those cases, removing the WM mask fairly often fixed the error in the border, although frequently the incorrect hypointensity label still remained in the WM segmentation. We tried to fix the errors in the WM–GM border and when unsuccessful, we simply excluded the ROI in question from analyses ( ). Of note, these errors can only be seen with the anatomical labels as overlays, unless they affect the WM–GM border. \\n  \\n (A,B)   Show a white matter (WM) hypointensity that affects the border between white and gray matter (WM–GM border), denoted by a yellow circle.   (C,D)   Show how the posterior part of the lateral ventricle causes distortion to the WM–GM border (yellow circle). If the error was not successfully fixed, all regions adjoining the error were excluded. \\n  \\nOne typical error occurred at the posterior end of the lateral ventricles, where it may cause segmentation errors in the adjacent cortical regions, typically the precuneus and the lingual gyrus. These regions were excluded from analyses when there was a distortion in the GM–WM border ( ), and included when there was no distortion in the border ( ). Unfortunately, hypointensities often appeared in ROI junctions, leading to exclusion of multiple regions due to one error ( ). Similar errors were seen in the ENIGMA protocol as well ( ). \\n\\n\\n##### Errors in Subcortical Labeling \\n  \\nPutamen was often mislabeled by FreeSurfer in our sample. Errors were addressed by adding control points, but the edits were largely unsuccessful. Consequently, we are currently working on separately validating subcortical segmentation procedures for our data ( ). All information regarding the subcortical labeling is presented in   ( , pages 15–16, Subcortex). \\n\\n\\n\\n#### ENIGMA Quality Control Protocol \\n  \\nAfter the quality control that entailed manual edits, we conducted a quality check with the ENIGMA Cortical Quality Control Protocol 2.0 (April 2017).  Therein, the FreeSurfer cortical surface measures were extracted and screened for statistical outliers using R  and visualized via Matlab (Mathworks) and bash scripts. Visual representations of the external 3D surface and internal 2D slices were generated and visually inspected according to the instructions provided by ENIGMA in   (at the time of writing). The ENIGMA Cortical quality check instructions remark how certain areas have a lot of anatomical variation and therefore they note the possibility to be more or less stringent in their quality control. Considering this and the fact that the example images provided in the ENIGMA instructions are limited in number and as such cannot show every variation, we deemed necessary to describe how we implemented these instructions in our sample. \\n\\n##### The External View \\n  \\nWe started by viewing the external image. The pre- and postcentral gyri were assessed for meninge overestimations, which can manifest as “spikes” ( ) or flat areas ( ). These error types were rare in our sample. These cases were excluded as instructed. \\n\\nThe supramarginal gyrus has a lot of anatomical variability and when quality checking it, we decided to be lenient as suggested by the ENIGMA instructions. We only excluded cases where the border between supramarginal and inferior parietal regions cuts through a gyrus, leading to discontinuous segments in one of the regions ( ). In some rare cases, this type of error also happened with the postcentral gyrus ( ), and these cases were also excluded. Similarly, in cases with supramarginal gyrus overestimation into the superior temporal gyrus, we only excluded clear errors (examples presented in  ). \\n  \\n (A)   Shows an error (yellow circle) where the inferior parietal area (purple) cuts through a whole gyrus in the supramarginal region (green). This area has a lot of variation and only clear errors led to exclusion in our ENIGMA quality control protocol.   (B)   Shows insula overestimation in the midline (green circle). Furthermore, the poor image quality can be seen the areas adjacent to the base of the skull, such as parahippocampal (green area denoted by a red arrow) and entorhinal (red area denoted be a white arrow). Additionally, there is an error in the border between superior frontal and caudal anterior cingulate. This border should follow the sulcal line. The rostral anterior cingulate was not considered erroneous in these cases. \\n  \\nOne commonly seen error is insula overestimation into the midline ( ). In these cases, we exclude insula and the region(s) adjacent to it in the midline (e.g., the medial orbitofrontal region in the case of  ). \\n\\nThe border between the superior frontal region and the cingulate cortex (  and  ) is one typical place for errors. A prominent paracingulate sulcus, that is more common on the left than on the right hemisphere, may cause underestimation of the cingulate cortex and consequently overestimation of the superior frontal region. This was typically seen on the left caudal anterior cingulate ( ), where we excluded the cases where the border did not follow sulcal lines anteriorly (as was demonstrated in the image examples in the instructions). In rare cases the border between posterior cingulate and superior frontal region was affected ( ), and these were also excluded. \\n\\nThe pericalcarine region was overestimated in some cases. According to the instructions cases where the segmentation is confined to the calcarine sulcus should be accepted. Therefore, we excluded cases where the pericalcarine region extended over a whole gyrus into the lingual gyrus or the cuneus. An example can be seen in  . \\n\\nCases of superior parietal overestimation were excluded as instructed. These errors were rare in our sample. Similarly, errors in the banks of the superior temporal sulcus were excluded as instructed. \\n\\nThe border between the middle and inferior temporal gyrus was not assessed, as the instructions suggested that most irregularities seen there are normal variants or relate to the viewing angle. \\n\\nSimilarly, we did not quality check the entorhinal/parahippocampal regions in the external view, as there is a lot of variation in the area. The ENIGMA instructions describe underestimations in 70–80% of cases. Furthermore, this region looks poor in practically all images (e.g., in  ) as do all the regions adjacent to the base of the skull and therefore, in our opinion, the quality assessment in those regions requires additional procedures, that are beyond the scope of the current study, to confirm their usability in statistical analyses. \\n\\n\\n##### The Internal View \\n  \\nIn the internal view, regions with unsegmented GM were excluded. These errors often reflect WM hypointensities seen in Freeview ( ). Interestingly, even quite large hypointensities do not necessarily equate to errors in the borders set by FreeSurfer and therefore do not always have an adverse effect on CT calculations. \\n\\nTemporal pole underestimations were sometimes seen. However, the cases were rarely as clear as presented in the instructions. Therefore, we had to use both coronal and axial views to assess the situation and make exclusions when both views supported an error in segmentation. \\n\\nOne of the errors commonly seen in our sample was the erroneous pial surface delineation in the lateral parts of the brain. This was particularly prevalent in the middle temporal gyri ( ). Notably, it is possible to attempt fixing these types of topological errors, e.g., by using control points or brainmask edits. Some previous studies (e.g.,  ) have done this. They reported average editing time of 9, 5 h, approximately quadruple our editing time, and concluded that the edits did not affect conclusions. Therefore, this type of edit was omitted as too time-consuming and challenging compared to the expected effect on results. The ROIs affected by these errors were excluded from analyses. This error was assessed from 2D slices, wherein what seems to be an error may be caused by partial volume effects. For example, in  , there seems to be a possible error on the right middle temporal region. If we look at the same image in Freeview, the same position seems to be segmented normally, especially when confirmed in the axial view ( ). Consequently, we only made exclusion when clear errors were seen in two adjacent slices. Particularly clear example of this can be seen in  , where the WM extends outside the segmentation. The error is also visible in the external view, where these regions do not appear as smooth as normally ( ), however the decisions to exclude a ROI were always made based on the internal view. This kind of error was significantly harder to recognize in Freeview and represents the most striking difference in results between the ENIGMA and Freeview quality control protocols. \\n  \\nThere are some visible errors in the lateral parts of the image (arrows). An especially clear error is denoted by the red circle, where some white matter is seen outside the cortical segmentation. \\n  \\n\\n##### Statistical Outliers \\n  \\nAfter the systematic viewing of all the problem regions, we inspected the statistical outliers. This rarely led to new exclusions, as many of the statistical outliers were among the excluded subjects or the outliers were ROIs where the instructions did not give any tools to assess whether they were correct. Therefore, we had to simply double check the internal view to rule out segmentation errors. \\n\\n\\n##### Enhancing Neuro Imaging Genetics Through Meta Analysis Exclusion Differences Between Edited and Unedited Images \\n  \\nWe performed the full ENIGMA quality control protocol for all edited images that were included in the ROI based analyses (  n   = 121). To assess how manual edits affect the number of excluded regions, we also performed the ENIGMA quality control protocol on a half sample (  n   = 61) of unedited images. In borderline cases (mostly regarding the borders between the supramarginal and superior temporal gyri as well as between the caudal anterior cingulate and superior frontal gyri) we consulted the ENIGMA quality control protocol of the edited images, to make the same ruling if the error was similar. Likewise, in the cases where the edited image passed the internal or external view without any ROI exclusions, but did not pass in the unedited version, the images were directly compared to each other to ensure the reason for not passing is an objective difference, as opposed to a human error or a different ruling in a borderline case. \\n\\n\\n\\n#### Exclusions \\n  \\nWe decided to use a dichotomous rating scale: pass or fail. The amount of motion artifact (marked by “concentric rings” or “waves”) and the clarity of the WM–GM border were assessed from the original T1 image. In borderline cases, we ran the standard recon-all and made new assessment based on the segmented image. Massive segmentation errors such as large missing areas or ubiquitous errors in WM–GM border were reasons for exclusion. Additionally, ENIGMA exclusion criteria were implemented as instructed. In some borderline cases, another expert rater assessed the image quality and agreement was reached to either include or exclude the image. Some images that were considered for inclusion but excluded after the first recon-all can be seen in  . These images had significantly more artifact than other images in our sample, although arguably they could have been included since the amount of artifact could be described as “moderate.” However, we decided to implement strict exclusion criteria to ensure high quality of data. \\n\\n\\n#### Alternate Processing: Optional Registration Flags in FreeSurfer \\n  \\nWe compared the FreeSurfer default recon all to recon-all with the “-mprage” and “-schwartzya3t-atlas” optional flags. All information regarding optional flags analyses is presented in   ( , pages 17–18, Optional flags). \\n\\n\\n#### Alternate Processing: CAT12 \\n  \\nA previous study conducted in the elderly demonstrated good agreement between FreeSurfer and CAT12 estimates of CT (  R   = 0.83), although CAT12 produced systematically higher values than FreeSurfer ( ). Therefore, we decided to explore the agreement between the two software in a pediatric population. All information regarding CAT12 analyses is presented in   ( , pages 19–25, CAT12). \\n\\n\\n\\n### Alternate Quality Control: Qoala-T \\n  \\nQoala-T is a supervised learning tool for quality control of automated labeling processed in FreeSurfer, and it is particularly intended for use in analysis of pediatric datasets ( ). We compared Qoala-T scores from all 134 participants that entered the FreeSurfer segmentation protocol, and the results are reported in   ( , pages 26–29, Qoala-T). \\n\\n\\n### Statistics \\n  \\nStatistical analyses were conducted using the IBM SPSS Statistics for Windows, version 25.0 (IBM Corp., Armonk, NY, United States). The ROI data was confirmed to be normally distributed using JMP Pro 15 (SAS Institute Inc., Cary, NC, United States) based on visual assessment and the similarity of mean and median values. \\n\\nTo compare the differences between the included (the participants that were included in ROI based analyses,   n   = 121) and excluded (all participants that lacked usable T1 data,   n   = 25) groups, we performed independent samples   t  -tests for age from birth at scan, gestational age at scan, gestational age at birth, birthweight, maternal age at term, and maternal body mass index (BMI) before pregnancy. In addition, we conducted Chi-Square tests for child gender, maternal education level (three classes: 1 = Upper secondary school or vocational school or lower, 2 = University of applied sciences, and 3 = University), maternal monthly income estimate after taxes (in euros, four classes: 1 = 1,500 or less, 2 = 1,501–2,500, 3 = 2,501–3,500, and 4 = 3,501 or more), maternal alcohol use during pregnancy (1 = yes, continued to some degree after learning about the pregnancy, 2 = yes, stopped after learning about the pregnancy, and 3 = no), maternal tobacco smoking during pregnancy (1 = yes, continued to some degree after learning about the pregnancy, 2 = yes, stopped after learning about the pregnancy, and 3 = no), maternal history of disease (allergies, depression, asthma, anxiety disorder, eating disorder, chronic urinary tract infection, autoimmune disorder, hypercholesterolemia, and hypertension), and maternal medication use at gestational week 14 (non-steroidal anti-inflammatory drugs, thyroxin, selective serotonin reuptake inhibitor [SSRI] or serotonin–norepinephrine reuptake inhibitor [SNRI], and corticosteroids), or at gestational week 34 (thyroxin, SSRI or SNRI, corticosteroids, and blood pressure medications). The categories in history of disease and medication during pregnancy were only included in statistical analyses, when there were at least four participants that had history of the disease or used the medication (to limit the chance of false positives). \\n\\nTo compare the exclusion rates between Freeview and ENIGMA quality control protocols, as well as between ENIGMA quality control protocols of edited and unedited images, we conducted Chi-Square tests (among all datapoints, single ROIs, and internal/external view passes in ENIGMA). \\n\\nThe inclusion criterion for the ROI based comparisons was passing the ENIGMA quality control protocol. To compare edited FreeSurfer to unedited FreeSurfer, we conducted a paired samples   t  -test. We calculated the absolute values of the change in CT between unedited and edited images for each ROI separately using the following formula: (C /C ) * 100%, where C  is the absolute value of the difference in mean CT between edited and unedited images and C  is the mean CT in the unedited images. Furthermore, we conducted a paired samples   t  -test with the mean CT values from all ROIs to measure the change between edited and unedited images. The same analyses were performed for WM SA and GM volume. \\n\\nTo assess the effects of manual editing and quality control on group comparison and brain structural asymmetry results, we conducted independent samples   t  -tests for sex differences in CT, SA, and volume measurements between a sample without quality control (  n   = 121 for every ROI) and the quality-controlled sample (maximum   n   = 121, where number of included ROIs varies). Using these same samples, we also conducted paired samples   t  -tests for the 34 ROIs in both hemispheres to examine structural asymmetry.  ,   output was created using JASP 0.16.1 ( ). \\n\\nAll significances were calculated 2-tailed (α = 0.05). To adjust for multiple comparisons in ROI-based analyses, we conducted the Bonferroni correction by setting the   p   value to 0.05 divided by the number of comparisons (=the number of ROIs = 68), resulting in   p   = 0.000735. We notify that the   p   value cut off for the current study is somewhat arbitrary and thus we also report the raw   p   values in the tables. \\n\\n\\n'\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  candidate_chunks[1].split('\\n', maxsplit=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Introduction ', '  \\nThere are multiple methodological challenges in pediatric neuroimaging studies that may affect quality of data and comparisons between studies. Magnetic resonance imaging (MRI) requires the subject to lie still while awake, which is more of a challenge with children than with adults ( ;  ;  ). This can lead to increased motion artifact. One study,   found that mild, moderate, and severe motion artifact were associated with 4, 7, and 27% loss of total gray matter (GM) volume in segmentation, respectively. Furthermore, subtle motion can cause bias even when a visible artifact is absent ( ). Another core challenge is the variation in preprocessing and segmentation techniques ( ), due to a lack of a “gold standard” processing pipeline for pediatric brain images. Therefore, some studies rightfully emphasize the importance of a validated quality control protocol ( ). \\n\\nFreeSurfer  is an open source software suite for processing brain MRI images that is commonly used in pediatric neuroimaging ( ;  ;  ;  ;  ;  ;  ;  ;  ;  ;  ;  ;  ;  ). The automated FreeSurfer segmentation protocol utilizes surface-based parcellation of cortical regions based on cortical folding patterns and   a priori   knowledge of anatomical structures (further technical information in  ;  ). The FreeSurfer instructions recommend to visually check and, when necessary, manually edit the data. The manual edits can fix errors in the automated segmentation such as skull-stripping, white matter (WM), or pial errors (errors in the outer border of cortical GM). The FreeSurfer instructions suggest that this process takes approximately 30 min. However, in our experience, this timeframe seems far too short for careful quality assessment and editing. \\n\\nThe time requirement is perhaps the most important practical challenge in manual editing of brain images. Another one is the fact that the edits may lead to inter- and intra-rater bias. Nevertheless, effects of motion artifact must be considered in the segmentation process ( ), as some systematic errors in pial border, subcortical structures, and the cerebellum have been observed in structural brain images of 5-year-olds without manual edits ( ). While a visual check for major errors has obvious benefits, the benefits of manual edits are not as clear in children ( ), adolescents ( ), or adults ( ;  ;  ) as errors that can be manually edited are often small and therefore only have minor effects on cortical thickness (CT), surface area (SA), or volume values. Consequently, they do not necessarily affect the significant findings in group comparisons ( ;  ) or brain–behavior relationships ( ). However, we argue that systematic manual edits of the segmented images can help with quality control as they simultaneously maximize the chance to find segmentation errors that can be subsequently fixed. \\n\\nQuality control is often done by applying a dichotomous pass or fail scale: either by simply excluding the cases with excessive motion artifact ( ;  ;  ;  ;  ;  ), excluding issues related to pathologies ( ;  ), excluding extreme outlier cases ( ), or it is simply noting that all images were considered to be of sufficient quality without a more detailed description of the criteria ( ). Another approach is to rate the image on a Likert scale from excellent or no motion artifact to unusable ( ;  ). One key challenge with this approach is that the exact borders between categories are very difficult to describe accurately in writing, and terms such as “subtle” and “significant” concentric bands or motion artifact are frequently used to draw the borders ( ;  ). Consequently, even if good intra- and inter-rater reliability can be reached within a study ( ), there can be large differences in how different studies define the categories. In many cases, the line of exclusion is drawn between moderate and severe ( ) or mild and moderate artifact ( ), and either way this fundamentally results in two categories: images with acceptable quality and images with unacceptable quality. Instead of a further quality classification via a Likert scale based on the amount of visible artifact, it might be beneficial to quality check all regions of interest (ROI) separately to verify high quality of the data. Especially considering the fact that the developing brain undergoes multiple non-linear growth patterns ( ;  ), which may cause issues when utilizing an adult template ( ;  ;  ), and local errors related to this challenge may be missed if quality check is based solely on the severity of visible motion artifact. \\n\\nIn this article, we propose a dichotomous rating scale for inclusion and exclusion of the images segmented with FreeSurfer, combined with a post-processing quality control protocol to visually confirm high quality data on a ROI level. For the automated segmentation tool in this protocol, we chose FreeSurfer based on the following practical advantages: (1) FreeSurfer has been validated for use in children between ages 4 and 11 years ( ), and multiple studies have used FreeSurfer to find brain associations between brain structure and risk factors or cognitive differences in children ( ;  ;  ); (2) FreeSurfer provides a method to accurately assess image quality and to fix certain types of errors via Freeview; and (3) Rigorous quality control protocols, such as the one provided by the ENIGMA consortium (Enhancing Neuro Imaging Genetics through Meta Analysis ), already exist for FreeSurfer to make final quality assessment on such a level that allows the researchers to exclude single ROIs with imperfect segmentation. We decided to use the ENIGMA quality control protocol, as it is widely used and accepted ( ), and has been successfully implemented for both adults ( ) and children ( ;  ). The manual edits instructed by FreeSurfer and rigorous ENIGMA quality control protocol were combined to form the semiautomated segmentation protocol used in the FinnBrain Neuroimaging Lab. \\n\\nIn the current study, we used a subsample of circa 5-year-olds that participated in MRI brain scans as part of the FinnBrain Birth Cohort Study. We give a detailed description of our manual editing and quality control protocol for T1-weighted MRI images in the FreeSurfer software suite. We used the ENIGMA quality control protocol and compare the findings to our protocol. This article aims to make our protocol very explicit and provide some guidelines on how one might assess image quality in a systematic manner across the sample (similar to  ). Furthermore, in a complementary analysis, we compared automated segmentation results between FreeSurfer and the statistical parametric mapping (SPM ) based computational anatomy toolbox (CAT12 ) to assess to the level of agreement. Finally, we compared the standard recon-all to other optional flags in FreeSurfer. \\n\\n']\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  candidate_chunks[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'\\n# Body\\n '\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  candidate_chunks[1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Introduction \\n  \\nThere are multiple methodological challenges in pediatric neuroimaging studies that may affect quality of data and comparisons between studies. Magnetic resonance imaging (MRI) requires the subject to lie still while awake, which is more of a challenge with children than with adults ( ;  ;  ). This can lead to increased motion artifact. One study,   found that mild, moderate, and severe motion artifact were associated with 4, 7, and 27% loss of total gray matter (GM) volume in segmentation, respectively. Furthermore, subtle motion can cause bias even when a visible artifact is absent ( ). Another core challenge is the variation in preprocessing and segmentation techniques ( ), due to a lack of a “gold standard” processing pipeline for pediatric brain images. Therefore, some studies rightfully emphasize the importance of a validated quality control protocol ( ). \\n\\nFreeSurfer  is an open source software suite for processing brain MRI images that is commonly used in pediatric neuroimaging ( ;  ;  ;  ;  ;  ;  ;  ;  ;  ;  ;  ;  ;  ). The automated FreeSurfer segmentation protocol utilizes surface-based parcellation of cortical regions based on cortical folding patterns and   a priori   knowledge of anatomical structures (further technical information in  ;  ). The FreeSurfer instructions recommend to visually check and, when necessary, manually edit the data. The manual edits can fix errors in the automated segmentation such as skull-stripping, white matter (WM), or pial errors (errors in the outer border of cortical GM). The FreeSurfer instructions suggest that this process takes approximately 30 min. However, in our experience, this timeframe seems far too short for careful quality assessment and editing. \\n\\nThe time requirement is perhaps the most important practical challenge in manual editing of brain images. Another one is the fact that the edits may lead to inter- and intra-rater bias. Nevertheless, effects of motion artifact must be considered in the segmentation process ( ), as some systematic errors in pial border, subcortical structures, and the cerebellum have been observed in structural brain images of 5-year-olds without manual edits ( ). While a visual check for major errors has obvious benefits, the benefits of manual edits are not as clear in children ( ), adolescents ( ), or adults ( ;  ;  ) as errors that can be manually edited are often small and therefore only have minor effects on cortical thickness (CT), surface area (SA), or volume values. Consequently, they do not necessarily affect the significant findings in group comparisons ( ;  ) or brain–behavior relationships ( ). However, we argue that systematic manual edits of the segmented images can help with quality control as they simultaneously maximize the chance to find segmentation errors that can be subsequently fixed. \\n\\nQuality control is often done by applying a dichotomous pass or fail scale: either by simply excluding the cases with excessive motion artifact ( ;  ;  ;  ;  ;  ), excluding issues related to pathologies ( ;  ), excluding extreme outlier cases ( ), or it is simply noting that all images were considered to be of sufficient quality without a more detailed description of the criteria ( ). Another approach is to rate the image on a Likert scale from excellent or no motion artifact to unusable ( ;  ). One key challenge with this approach is that the exact borders between categories are very difficult to describe accurately in writing, and terms such as “subtle” and “significant” concentric bands or motion artifact are frequently used to draw the borders ( ;  ). Consequently, even if good intra- and inter-rater reliability can be reached within a study ( ), there can be large differences in how different studies define the categories. In many cases, the line of exclusion is drawn between moderate and severe ( ) or mild and moderate artifact ( ), and either way this fundamentally results in two categories: images with acceptable quality and images with unacceptable quality. Instead of a further quality classification via a Likert scale based on the amount of visible artifact, it might be beneficial to quality check all regions of interest (ROI) separately to verify high quality of the data. Especially considering the fact that the developing brain undergoes multiple non-linear growth patterns ( ;  ), which may cause issues when utilizing an adult template ( ;  ;  ), and local errors related to this challenge may be missed if quality check is based solely on the severity of visible motion artifact. \\n\\nIn this article, we propose a dichotomous rating scale for inclusion and exclusion of the images segmented with FreeSurfer, combined with a post-processing quality control protocol to visually confirm high quality data on a ROI level. For the automated segmentation tool in this protocol, we chose FreeSurfer based on the following practical advantages: (1) FreeSurfer has been validated for use in children between ages 4 and 11 years ( ), and multiple studies have used FreeSurfer to find brain associations between brain structure and risk factors or cognitive differences in children ( ;  ;  ); (2) FreeSurfer provides a method to accurately assess image quality and to fix certain types of errors via Freeview; and (3) Rigorous quality control protocols, such as the one provided by the ENIGMA consortium (Enhancing Neuro Imaging Genetics through Meta Analysis ), already exist for FreeSurfer to make final quality assessment on such a level that allows the researchers to exclude single ROIs with imperfect segmentation. We decided to use the ENIGMA quality control protocol, as it is widely used and accepted ( ), and has been successfully implemented for both adults ( ) and children ( ;  ). The manual edits instructed by FreeSurfer and rigorous ENIGMA quality control protocol were combined to form the semiautomated segmentation protocol used in the FinnBrain Neuroimaging Lab. \\n\\nIn the current study, we used a subsample of circa 5-year-olds that participated in MRI brain scans as part of the FinnBrain Birth Cohort Study. We give a detailed description of our manual editing and quality control protocol for T1-weighted MRI images in the FreeSurfer software suite. We used the ENIGMA quality control protocol and compare the findings to our protocol. This article aims to make our protocol very explicit and provide some guidelines on how one might assess image quality in a systematic manner across the sample (similar to  ). Furthermore, in a complementary analysis, we compared automated segmentation results between FreeSurfer and the statistical parametric mapping (SPM ) based computational anatomy toolbox (CAT12 ) to assess to the level of agreement. Finally, we compared the standard recon-all to other optional flags in FreeSurfer. \\n\\n'\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  chunk\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Materials and Methods \\n  \\nThis study was conducted in accordance with the Declaration of Helsinki, and it was approved by the Joint Ethics Committee of the University of Turku and the Hospital District of Southwest Finland (07.08.2018) §330, ETMK: 31/180/2011. \\n\\n### Participants \\n  \\nThe participants are part of the FinnBrain Birth Cohort Study  ( ), where 5-year-olds were invited to neuropsychological, logopedic, neuroimaging, and pediatric study visits. For the neuroimaging visit, we primarily recruited participants that had a prior visit to neuropsychological measurements at circa 5 years of age (  n   = 141/146). However, there were a few exceptions: three participants were included without a neuropsychological visit, as they had an exposure to maternal prenatal synthetic glucocorticoid treatment (recruited separately for a nested case–control sub-study). The data additionally includes two participants that were enrolled for pilot scans. We aimed to scan all subjects between the ages 5 years 3 months and 5 years 5 months, and 135/146 (92%) of the participants attended the visit within this timeframe (reasons to scan outside the timeframe include, for example, the family moving the visit to a later date). The exclusion criteria for this study were: (1) born before gestational week 35 (before gestational week 32 for those with exposure to maternal prenatal synthetic glucocorticoid treatment), (2) developmental anomaly or abnormalities in senses or communication (e.g., blindness, deafness, and congenital heart disease), (3) known long-term medical diagnosis (e.g., epilepsy and autism), (4) ongoing medical examinations or clinical follow up in a hospital (meaning there has been a referral from primary care setting to special health care), (5) child use of continuous, daily medication (including per oral medications, topical creams, and inhalants. One exception to this was desmopressin ( Minirin) medication, which was allowed), (6) history of head trauma (defined as concussion necessitating clinical follow up in a health care setting or worse), (7) metallic (golden) ear tubes (to assure good-quality scans), and routine MRI contraindications. \\n\\nIn the current study, we used a subsample (approximately two thirds of the full sample) that consists of the participants that were scanned before a temporary stop to visits due to the restrictions caused by the coronavirus disease 2019 (COVID-19) pandemic. The scans were performed between 29 October, 2017 and 1 March, 2020. We contacted 415 families and reached 363 (87%) of them. In total, 146 (40% of the reached families) participants attended imaging visits (one pair of twins, one participant attended twice, and only the latter scan was included). Eight of them did not start the scan, and four were excluded due to excess motion artifact in the T1-image. Thereafter, 134 T1 images (mean age 5.34 years, SD 0.06 years, range 5.08–5.22 years, 72 boys, 62 girls) entered the processing pipelines.   presents the demographic data as recommended in our earlier review ( ). A flowchart depicting the formation of the final sample through the different exclusion steps is presented in  . \\n  \\nA flowchart depicting the steps leading to our final sample size of 121. The region of interest (ROI) exclusions are presented in  . \\n  \\n\\n### The Study Visits \\n  \\nAll MRI scans were performed for research purposes by the research staff (one research nurse, four Ph.D. students, and two MR technologists). Before the visit, each family was personally contacted and recruited via telephone calls by a research staff member. The scan preparations started with the recruitment and at home training. We introduced the image acquisition process to the parents and advised them to explain the process to their children and confirm child assent before the follow up phone call that was used to confirm the willingness to participate. Thereafter, we advised the parents to use at home familiarization methods such as showing a video describing the visit, playing audio of scanner sounds, encouraging the child to lie still like a statue (“statue game”), and practicing with a homemade mock scanner, e.g., a cardboard box with a hole to view a movie through. The visit was marketed to the participants as a “space adventure,” which is in principle similar to the previously described “submarine protocol” ( ) but the child was allowed to come up with other settings as well. A member of the research staff made a home visit before the scan to deliver earplugs and headphones, to give more detailed information about the visit, and to answer any remaining questions. An added benefit of the home visit was the chance to meet the participating child and that way start the familiarization with the research staff. \\n\\nAt the start of the visit, we familiarized the participant with the research team (research nurse and a medically trained Ph.D. student) and acquired written informed consent from both parents. This first portion of the visit included a practice session using a non-commercial mock scanner consisting of a toy tunnel and a homemade wooden head coil. Inexpensive non-commercial mock scanners have been shown to be as effective as commercial ones ( ). The participants brought at least one of their toys that would undergo a mock scan (e.g., an MRI compatible stuffed animal they could also bring with them into the real scanner). The researcher played scanner sounds on their cell phone during the mock scan and the child could take pictures of the toy lying still and of the toy being moved by the researcher to demonstrate the importance of lying still during the scan. Communication during the scan was practiced. Overall, these preparations at the scan site were highly variable as we did our best to accommodate to befit the child characteristics (e.g., taking into account the physical activity and anxiety) in cooperation with the family. Finally, we served a light meal of the participant’s choice before the scan. \\n\\nThe participants were scanned awake or during natural sleep. One member of the research staff and parent(s) stayed in the scanner room throughout the whole scan. During the scan, participants wore earplugs and headphones. Through the headphones, they were able to listen to the movie or TV show of their choice while watching it with the help of mirrors fitted into the head coil (the TV was located at the foot of the bed of the scanner). Some foam padding was applied to help the head stay still and assure comfortable position. Participants were given a “signal ball” to throw in case they needed or wanted to stop or pause the scan (e.g., to visit the toilet). If the research staff member noticed movement, they gently reminded the participant to stay still by lightly touching their foot. This method of communication was agreed on earlier in the visit and was planned to convey a clear signal of presence while minimizing the tactile stimulation. Many of the methods used to reduce anxiety and motion during the scan have been described in earlier studies ( ;  ). \\n\\nAll images were viewed by one neuroradiologist (RP) who then consulted a pediatric neurologist (TL) when necessary. There were four (out of 146, 2.7%) cases with an incidental finding that required consultation. All four cases initially entered the FreeSurfer processing pipeline and three were included in the final ROI based analyses. The protocol with incidental findings has been described in our earlier work ( ), and a separate report of their incidence is in preparation for the eventual full data set. \\n\\n\\n### Magnetic Resonance Imaging Data Acquisition \\n  \\nParticipants were scanned using a Siemens Magnetom Skyra fit 3T with a 20-element head/neck matrix coil. We used Generalized Autocalibrating Partially Parallel Acquisition (GRAPPA) technique to accelerate image acquisition [parallel acquisition technique (PAT) factor of 2 was used]. The MRI data was acquired as a part of max. 60-min scan protocol. The scans included a high resolution T1 magnetization prepared rapid gradient echo (MPRAGE), a T2 turbo spin echo (TSE), a 7-min resting state functional MRI, and a 96-direction single shell (b = 1,000 s/mm ) diffusion tensor imaging (DTI) sequence ( ) as well as a 31-direction with b = 650 s/mm  and a 80-direction with b = 2,000 s/mm . For the purposes of the current study, we acquired high resolution T1-weighted images with the following sequence parameters: repetition time (TR) = 1,900 ms, echo time (TE) = 3.26 ms, inversion time (TI) = 900 ms, flip angle = 9 degrees, voxel size = 1.0 × 1.0 × 1.0 mm , and field of view (FOV) 256 × 256 mm . The scans were planned as per recommendations of the FreeSurfer developers. \\n\\n\\n### Data Processing \\n  \\n#### FreeSurfer \\n  \\nCortical reconstruction and volumetric segmentation for all 134 images were performed with the FreeSurfer software suite, version 6.0.0.  We selected the T1 image with the least motion artifact (in case there were several attempts due to visible motion during scan) and then applied the “recon-all” processing stream with default parameters. It begins with transformation to Talaraich space, intensity inhomogeneity correction, bias field correction ( ), and skull-stripping ( ). Thereafter, WM is separated from GM and other tissues and the volume within the created WM–GM boundary is filled. After this, the surface is tessellated and smoothed. After these preprocessing steps are completed, the surface is inflated ( ) and registered to a spherical atlas. This method adapts to the folding pattern of each individual brain, utilizing consistent folding patterns such as the central sulcus and the sylvian fissure as landmarks, allowing for high localization accuracy ( ). FreeSurfer uses probabilistic approach based on Markov random fields for automated labeling of brain regions. Cortical thickness is calculated as the average distance between the WM–GM boundary and the pial surface on the tessellated surface ( ). The cortical thickness measurement technique has been validated against post-mortem histological ( ) and manual measurements ( ;  ). \\n\\n\\n#### FreeSurfer Manual Edits and the Freeview Quality Control Protocol \\n  \\nWe used Freeview to view and edit the images using the standard command recommended by the FreeSurfer instructions with the addition of the Desikan–Killiany atlas that allowed us to correctly identify the ROIs where errors were found. Images with excess motion artifact or large unsegmented regions (extending over multiple gyri, examples provided in  ) were excluded. There were 13 participants that were excluded due to erroneous segmentation. The images that passed the initial quality check were then manually edited (the time required for manual editing ranged from 45 min in high quality images to over 3 h in images with a lot of artifact, taking approximately 2 h on average). All images were examined in all three directions one hemisphere at a time and the edits were made for every slice regardless of the ROI in question. Subsequently, we ran the automated segmentation process again as suggested by FreeSurfer instructions. The images were then inspected again for errors, and the ROIs with errors that affect WM–GM or pial borders were excluded in the Freeview quality control protocol. The Freeview protocol presented in this study was adapted locally for the FinnBrain Neuroimaging Lab as a method to assess errors in a slice-by-slice view from the official quality control procedure provided in the FreeSurfer instructions.  We also provide a practical application manual in   ( , pages 3–9, FreeSurfer editing) that we give to new researchers when they start practicing the FinnBrain manual editing and quality control protocol. \\n\\n##### Errors in Borders \\n  \\nThe automatically segmented images generated by FreeSurfer software suite were visually inspected and the found errors were either manually corrected or the ROI with the error was simply excluded depending on the type of error. Excess parts of the skull were removed where the pial border was affected by them ( ). Arteries were removed to avoid segmentation errors between arteries and WM (especially relevant for anterior temporal areas and the insulae). This was done by setting the eraser to only delete voxels with intensity between 130 and 190 in the brainmask volume. The arteries were removed throughout the image with no regard to whether they caused issues in the segmentation on that specific slice. An example can be seen in  . In cases where an error appeared in a junction between ROIs, all adjoining ROIs were excluded. \\n  \\nA presentation of some common errors and fixes related to the pial border and non-brain tissues.   (A)   Demonstrates how skull fragments can cause errors in pial border (yellow circles).   (B)   Presents the same subject with skull fragments removed. In panel   (C)  , arteries were removed (green circle). We removed voxels with an intensity between 130 and 190, and therefore some parts of arteries were not removed (yellow circle).   (C)   Also demonstrates the challenges with artifact, meninges, and the pial border. In some areas, the pial border may extend into the meninges (yellow arrows). Meanwhile, at the other end of the same gyrus, the border may seem correct (green arrows). It is difficult to fix these errors manually. Additionally, the visible motion artifact adds further challenges to manual edits of the pial border. In panel   (D)  , the pial border cuts through a gyrus. \\n  \\nOne typical error was that parts of the superior sagittal sinus (SSS) were included within the pial border. We stopped editing the SSS after an interim assessment as it was an arduous task with little effect on final results. All information regarding SSS edits is presented in   ( , pages 10–14, Superior sagittal sinus). \\n\\nIn addition, there were errors that could not be fixed easily. In some cases, the pial border may cut through the cortex (  shows an error in the left rostral middle frontal region). In these cases, the remaining GM mask is too small, and this error cannot be easily fixed in Freeview. Manual segmentation of a T1 image is labor intensive and hard to conduct reliably with 1 mm  resolution even when the edits would cover small areas. Moreover, the FreeSurfer instructions do not recommend this approach. Additionally, the WM mask edits recommended in FreeSurfer instructions would not fix all cases where the cortical segmentation is too thin, as the WM mask often seemed adequate in these areas (an example presented in  ). Therefore, we simply had to exclude the ROI(s) in question. \\n\\nSmall errors of the WM–GM border were prevalent throughout the brain. The corrections were made by erasing excess WM mask. This process is demonstrated in  . WM–GM border was inspected after the manual edits. A continuous error of at least ten slices in the coronal view led to exclusion of all the ROIs directly impacted by the error. Furthermore, ubiquitous errors in the WM–GM border, as markers of motion artifact, led to exclusion of the whole brain (as in  ). \\n  \\nA demonstration of our white matter (WM) mask editing protocol.   (A)   Shows a typical error in the border between white and gray matter (WM–GM border), where it extends too close to the pial border. Errors such as this are searched for in the “brainmask” volume   (A,D)  .   (B)   Shows the same error in “wm” volume with “Jet” colormap   (B,C)  .   (C)   Shows how we fixed these errors by erasing the erroneous WM mask (blue voxels).   (D)   Shows the final result after the second recon-all. \\n    \\nTwo examples of excluded brain images.   (A)   Shows “waves” throughout the image, marking motion artifact.   (B)   Shows the same subject as in panel   (A)   in a coronal view and borders visible. This image shows motion artifact related errors in the border between white and gray matter (WM–GM border), denoted by the yellow circle. Additionally, there is potential unsegmented area due to motion artifact (green circle) and poor contrast between WM and GM (white circle).   (C,D)   Show another excluded subject. The motion artifact in panel   (C)   is not as pronounced as in panel   (A)  . However,   (D)   still shows some typical errors for images with much artifact. There is a clear pial error (white arrow). Additionally, the yellow arrows show typical cases, where the “ringing” causes the WM mask to “widen” where the actual WM meets the ringing motion artifact. \\n  \\nFurthermore, there are some error types that cannot be easily fixed but also do not warrant exclusion. One such problem is that the pial border often extends into the cerebrospinal fluid or meninges around the brain ( ). The issue with this type of error is that sometimes the real border between GM and the surrounding meninges cannot be denoted visually and therefore the error cannot be reliably fixed. This problem is further complicated by the fact that motion artifact may mimic the border between GM and meninges making the visual quality control challenging (  and  ). In addition to motion, fat shift can also cause this type of artifact. The amount of fat shift in images is dependent on the imaging protocol, more specifically the bandwidth of the acquisition. \\n\\nThere were some minor incongruities in multiple images. A common example can be seen in  , where there seems to be a potential error in the pial border. Areas like this look normal in other planes. A less common example is shown in  , where there is an apparent discontinuation in the WM–GM border. Similarly, there was no discontinuation in other planes. Both these minor incongruities were considered partial volume effects related to the presentation of a 3D surface in 2D slices. Therefore, both cases were included. \\n\\n\\n##### Errors in Cortical Labeling \\n  \\nA common issue was the presence of WM hypointensities in the segmented images. They sometimes erroneously appeared in the cortex. These errors were typically small and did not cause errors in pial or WM–GM borders ( ), and in those cases did not require exclusion. The hypointensities themselves were rarely successfully fixed by editing the WM mask and therefore were left unedited unless they caused errors in the GM–WM border. In those cases, removing the WM mask fairly often fixed the error in the border, although frequently the incorrect hypointensity label still remained in the WM segmentation. We tried to fix the errors in the WM–GM border and when unsuccessful, we simply excluded the ROI in question from analyses ( ). Of note, these errors can only be seen with the anatomical labels as overlays, unless they affect the WM–GM border. \\n  \\n (A,B)   Show a white matter (WM) hypointensity that affects the border between white and gray matter (WM–GM border), denoted by a yellow circle.   (C,D)   Show how the posterior part of the lateral ventricle causes distortion to the WM–GM border (yellow circle). If the error was not successfully fixed, all regions adjoining the error were excluded. \\n  \\nOne typical error occurred at the posterior end of the lateral ventricles, where it may cause segmentation errors in the adjacent cortical regions, typically the precuneus and the lingual gyrus. These regions were excluded from analyses when there was a distortion in the GM–WM border ( ), and included when there was no distortion in the border ( ). Unfortunately, hypointensities often appeared in ROI junctions, leading to exclusion of multiple regions due to one error ( ). Similar errors were seen in the ENIGMA protocol as well ( ). \\n\\n\\n##### Errors in Subcortical Labeling \\n  \\nPutamen was often mislabeled by FreeSurfer in our sample. Errors were addressed by adding control points, but the edits were largely unsuccessful. Consequently, we are currently working on separately validating subcortical segmentation procedures for our data ( ). All information regarding the subcortical labeling is presented in   ( , pages 15–16, Subcortex). \\n\\n\\n\\n#### ENIGMA Quality Control Protocol \\n  \\nAfter the quality control that entailed manual edits, we conducted a quality check with the ENIGMA Cortical Quality Control Protocol 2.0 (April 2017).  Therein, the FreeSurfer cortical surface measures were extracted and screened for statistical outliers using R  and visualized via Matlab (Mathworks) and bash scripts. Visual representations of the external 3D surface and internal 2D slices were generated and visually inspected according to the instructions provided by ENIGMA in   (at the time of writing). The ENIGMA Cortical quality check instructions remark how certain areas have a lot of anatomical variation and therefore they note the possibility to be more or less stringent in their quality control. Considering this and the fact that the example images provided in the ENIGMA instructions are limited in number and as such cannot show every variation, we deemed necessary to describe how we implemented these instructions in our sample. \\n\\n##### The External View \\n  \\nWe started by viewing the external image. The pre- and postcentral gyri were assessed for meninge overestimations, which can manifest as “spikes” ( ) or flat areas ( ). These error types were rare in our sample. These cases were excluded as instructed. \\n\\nThe supramarginal gyrus has a lot of anatomical variability and when quality checking it, we decided to be lenient as suggested by the ENIGMA instructions. We only excluded cases where the border between supramarginal and inferior parietal regions cuts through a gyrus, leading to discontinuous segments in one of the regions ( ). In some rare cases, this type of error also happened with the postcentral gyrus ( ), and these cases were also excluded. Similarly, in cases with supramarginal gyrus overestimation into the superior temporal gyrus, we only excluded clear errors (examples presented in  ). \\n  \\n (A)   Shows an error (yellow circle) where the inferior parietal area (purple) cuts through a whole gyrus in the supramarginal region (green). This area has a lot of variation and only clear errors led to exclusion in our ENIGMA quality control protocol.   (B)   Shows insula overestimation in the midline (green circle). Furthermore, the poor image quality can be seen the areas adjacent to the base of the skull, such as parahippocampal (green area denoted by a red arrow) and entorhinal (red area denoted be a white arrow). Additionally, there is an error in the border between superior frontal and caudal anterior cingulate. This border should follow the sulcal line. The rostral anterior cingulate was not considered erroneous in these cases. \\n  \\nOne commonly seen error is insula overestimation into the midline ( ). In these cases, we exclude insula and the region(s) adjacent to it in the midline (e.g., the medial orbitofrontal region in the case of  ). \\n\\nThe border between the superior frontal region and the cingulate cortex (  and  ) is one typical place for errors. A prominent paracingulate sulcus, that is more common on the left than on the right hemisphere, may cause underestimation of the cingulate cortex and consequently overestimation of the superior frontal region. This was typically seen on the left caudal anterior cingulate ( ), where we excluded the cases where the border did not follow sulcal lines anteriorly (as was demonstrated in the image examples in the instructions). In rare cases the border between posterior cingulate and superior frontal region was affected ( ), and these were also excluded. \\n\\nThe pericalcarine region was overestimated in some cases. According to the instructions cases where the segmentation is confined to the calcarine sulcus should be accepted. Therefore, we excluded cases where the pericalcarine region extended over a whole gyrus into the lingual gyrus or the cuneus. An example can be seen in  . \\n\\nCases of superior parietal overestimation were excluded as instructed. These errors were rare in our sample. Similarly, errors in the banks of the superior temporal sulcus were excluded as instructed. \\n\\nThe border between the middle and inferior temporal gyrus was not assessed, as the instructions suggested that most irregularities seen there are normal variants or relate to the viewing angle. \\n\\nSimilarly, we did not quality check the entorhinal/parahippocampal regions in the external view, as there is a lot of variation in the area. The ENIGMA instructions describe underestimations in 70–80% of cases. Furthermore, this region looks poor in practically all images (e.g., in  ) as do all the regions adjacent to the base of the skull and therefore, in our opinion, the quality assessment in those regions requires additional procedures, that are beyond the scope of the current study, to confirm their usability in statistical analyses. \\n\\n\\n##### The Internal View \\n  \\nIn the internal view, regions with unsegmented GM were excluded. These errors often reflect WM hypointensities seen in Freeview ( ). Interestingly, even quite large hypointensities do not necessarily equate to errors in the borders set by FreeSurfer and therefore do not always have an adverse effect on CT calculations. \\n\\nTemporal pole underestimations were sometimes seen. However, the cases were rarely as clear as presented in the instructions. Therefore, we had to use both coronal and axial views to assess the situation and make exclusions when both views supported an error in segmentation. \\n\\nOne of the errors commonly seen in our sample was the erroneous pial surface delineation in the lateral parts of the brain. This was particularly prevalent in the middle temporal gyri ( ). Notably, it is possible to attempt fixing these types of topological errors, e.g., by using control points or brainmask edits. Some previous studies (e.g.,  ) have done this. They reported average editing time of 9, 5 h, approximately quadruple our editing time, and concluded that the edits did not affect conclusions. Therefore, this type of edit was omitted as too time-consuming and challenging compared to the expected effect on results. The ROIs affected by these errors were excluded from analyses. This error was assessed from 2D slices, wherein what seems to be an error may be caused by partial volume effects. For example, in  , there seems to be a possible error on the right middle temporal region. If we look at the same image in Freeview, the same position seems to be segmented normally, especially when confirmed in the axial view ( ). Consequently, we only made exclusion when clear errors were seen in two adjacent slices. Particularly clear example of this can be seen in  , where the WM extends outside the segmentation. The error is also visible in the external view, where these regions do not appear as smooth as normally ( ), however the decisions to exclude a ROI were always made based on the internal view. This kind of error was significantly harder to recognize in Freeview and represents the most striking difference in results between the ENIGMA and Freeview quality control protocols. \\n  \\nThere are some visible errors in the lateral parts of the image (arrows). An especially clear error is denoted by the red circle, where some white matter is seen outside the cortical segmentation. \\n  \\n\\n##### Statistical Outliers \\n  \\nAfter the systematic viewing of all the problem regions, we inspected the statistical outliers. This rarely led to new exclusions, as many of the statistical outliers were among the excluded subjects or the outliers were ROIs where the instructions did not give any tools to assess whether they were correct. Therefore, we had to simply double check the internal view to rule out segmentation errors. \\n\\n\\n##### Enhancing Neuro Imaging Genetics Through Meta Analysis Exclusion Differences Between Edited and Unedited Images \\n  \\nWe performed the full ENIGMA quality control protocol for all edited images that were included in the ROI based analyses (  n   = 121). To assess how manual edits affect the number of excluded regions, we also performed the ENIGMA quality control protocol on a half sample (  n   = 61) of unedited images. In borderline cases (mostly regarding the borders between the supramarginal and superior temporal gyri as well as between the caudal anterior cingulate and superior frontal gyri) we consulted the ENIGMA quality control protocol of the edited images, to make the same ruling if the error was similar. Likewise, in the cases where the edited image passed the internal or external view without any ROI exclusions, but did not pass in the unedited version, the images were directly compared to each other to ensure the reason for not passing is an objective difference, as opposed to a human error or a different ruling in a borderline case. \\n\\n\\n\\n#### Exclusions \\n  \\nWe decided to use a dichotomous rating scale: pass or fail. The amount of motion artifact (marked by “concentric rings” or “waves”) and the clarity of the WM–GM border were assessed from the original T1 image. In borderline cases, we ran the standard recon-all and made new assessment based on the segmented image. Massive segmentation errors such as large missing areas or ubiquitous errors in WM–GM border were reasons for exclusion. Additionally, ENIGMA exclusion criteria were implemented as instructed. In some borderline cases, another expert rater assessed the image quality and agreement was reached to either include or exclude the image. Some images that were considered for inclusion but excluded after the first recon-all can be seen in  . These images had significantly more artifact than other images in our sample, although arguably they could have been included since the amount of artifact could be described as “moderate.” However, we decided to implement strict exclusion criteria to ensure high quality of data. \\n\\n\\n#### Alternate Processing: Optional Registration Flags in FreeSurfer \\n  \\nWe compared the FreeSurfer default recon all to recon-all with the “-mprage” and “-schwartzya3t-atlas” optional flags. All information regarding optional flags analyses is presented in   ( , pages 17–18, Optional flags). \\n\\n\\n#### Alternate Processing: CAT12 \\n  \\nA previous study conducted in the elderly demonstrated good agreement between FreeSurfer and CAT12 estimates of CT (  R   = 0.83), although CAT12 produced systematically higher values than FreeSurfer ( ). Therefore, we decided to explore the agreement between the two software in a pediatric population. All information regarding CAT12 analyses is presented in   ( , pages 19–25, CAT12). \\n\\n\\n\\n### Alternate Quality Control: Qoala-T \\n  \\nQoala-T is a supervised learning tool for quality control of automated labeling processed in FreeSurfer, and it is particularly intended for use in analysis of pediatric datasets ( ). We compared Qoala-T scores from all 134 participants that entered the FreeSurfer segmentation protocol, and the results are reported in   ( , pages 26–29, Qoala-T). \\n\\n\\n### Statistics \\n  \\nStatistical analyses were conducted using the IBM SPSS Statistics for Windows, version 25.0 (IBM Corp., Armonk, NY, United States). The ROI data was confirmed to be normally distributed using JMP Pro 15 (SAS Institute Inc., Cary, NC, United States) based on visual assessment and the similarity of mean and median values. \\n\\nTo compare the differences between the included (the participants that were included in ROI based analyses,   n   = 121) and excluded (all participants that lacked usable T1 data,   n   = 25) groups, we performed independent samples   t  -tests for age from birth at scan, gestational age at scan, gestational age at birth, birthweight, maternal age at term, and maternal body mass index (BMI) before pregnancy. In addition, we conducted Chi-Square tests for child gender, maternal education level (three classes: 1 = Upper secondary school or vocational school or lower, 2 = University of applied sciences, and 3 = University), maternal monthly income estimate after taxes (in euros, four classes: 1 = 1,500 or less, 2 = 1,501–2,500, 3 = 2,501–3,500, and 4 = 3,501 or more), maternal alcohol use during pregnancy (1 = yes, continued to some degree after learning about the pregnancy, 2 = yes, stopped after learning about the pregnancy, and 3 = no), maternal tobacco smoking during pregnancy (1 = yes, continued to some degree after learning about the pregnancy, 2 = yes, stopped after learning about the pregnancy, and 3 = no), maternal history of disease (allergies, depression, asthma, anxiety disorder, eating disorder, chronic urinary tract infection, autoimmune disorder, hypercholesterolemia, and hypertension), and maternal medication use at gestational week 14 (non-steroidal anti-inflammatory drugs, thyroxin, selective serotonin reuptake inhibitor [SSRI] or serotonin–norepinephrine reuptake inhibitor [SNRI], and corticosteroids), or at gestational week 34 (thyroxin, SSRI or SNRI, corticosteroids, and blood pressure medications). The categories in history of disease and medication during pregnancy were only included in statistical analyses, when there were at least four participants that had history of the disease or used the medication (to limit the chance of false positives). \\n\\nTo compare the exclusion rates between Freeview and ENIGMA quality control protocols, as well as between ENIGMA quality control protocols of edited and unedited images, we conducted Chi-Square tests (among all datapoints, single ROIs, and internal/external view passes in ENIGMA). \\n\\nThe inclusion criterion for the ROI based comparisons was passing the ENIGMA quality control protocol. To compare edited FreeSurfer to unedited FreeSurfer, we conducted a paired samples   t  -test. We calculated the absolute values of the change in CT between unedited and edited images for each ROI separately using the following formula: (C /C ) * 100%, where C  is the absolute value of the difference in mean CT between edited and unedited images and C  is the mean CT in the unedited images. Furthermore, we conducted a paired samples   t  -test with the mean CT values from all ROIs to measure the change between edited and unedited images. The same analyses were performed for WM SA and GM volume. \\n\\nTo assess the effects of manual editing and quality control on group comparison and brain structural asymmetry results, we conducted independent samples   t  -tests for sex differences in CT, SA, and volume measurements between a sample without quality control (  n   = 121 for every ROI) and the quality-controlled sample (maximum   n   = 121, where number of included ROIs varies). Using these same samples, we also conducted paired samples   t  -tests for the 34 ROIs in both hemispheres to examine structural asymmetry.  ,   output was created using JASP 0.16.1 ( ). \\n\\nAll significances were calculated 2-tailed (α = 0.05). To adjust for multiple comparisons in ROI-based analyses, we conducted the Bonferroni correction by setting the   p   value to 0.05 divided by the number of comparisons (=the number of ROIs = 68), resulting in   p   = 0.000735. We notify that the   p   value cut off for the current study is somewhat arbitrary and thus we also report the raw   p   values in the tables. \\n\\n\\n'\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  chunk\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Materials and Methods \\n  \\nThis study was conducted in accordance with the Declaration of Helsinki, and it was approved by the Joint Ethics Committee of the University of Turku and the Hospital District of Southwest Finland (07.08.2018) §330, ETMK: 31/180/2011. \\n\\n### Participants \\n  \\nThe participants are part of the FinnBrain Birth Cohort Study  ( ), where 5-year-olds were invited to neuropsychological, logopedic, neuroimaging, and pediatric study visits. For the neuroimaging visit, we primarily recruited participants that had a prior visit to neuropsychological measurements at circa 5 years of age (  n   = 141/146). However, there were a few exceptions: three participants were included without a neuropsychological visit, as they had an exposure to maternal prenatal synthetic glucocorticoid treatment (recruited separately for a nested case–control sub-study). The data additionally includes two participants that were enrolled for pilot scans. We aimed to scan all subjects between the ages 5 years 3 months and 5 years 5 months, and 135/146 (92%) of the participants attended the visit within this timeframe (reasons to scan outside the timeframe include, for example, the family moving the visit to a later date). The exclusion criteria for this study were: (1) born before gestational week 35 (before gestational week 32 for those with exposure to maternal prenatal synthetic glucocorticoid treatment), (2) developmental anomaly or abnormalities in senses or communication (e.g., blindness, deafness, and congenital heart disease), (3) known long-term medical diagnosis (e.g., epilepsy and autism), (4) ongoing medical examinations or clinical follow up in a hospital (meaning there has been a referral from primary care setting to special health care), (5) child use of continuous, daily medication (including per oral medications, topical creams, and inhalants. One exception to this was desmopressin ( Minirin) medication, which was allowed), (6) history of head trauma (defined as concussion necessitating clinical follow up in a health care setting or worse), (7) metallic (golden) ear tubes (to assure good-quality scans), and routine MRI contraindications. \\n\\nIn the current study, we used a subsample (approximately two thirds of the full sample) that consists of the participants that were scanned before a temporary stop to visits due to the restrictions caused by the coronavirus disease 2019 (COVID-19) pandemic. The scans were performed between 29 October, 2017 and 1 March, 2020. We contacted 415 families and reached 363 (87%) of them. In total, 146 (40% of the reached families) participants attended imaging visits (one pair of twins, one participant attended twice, and only the latter scan was included). Eight of them did not start the scan, and four were excluded due to excess motion artifact in the T1-image. Thereafter, 134 T1 images (mean age 5.34 years, SD 0.06 years, range 5.08–5.22 years, 72 boys, 62 girls) entered the processing pipelines.   presents the demographic data as recommended in our earlier review ( ). A flowchart depicting the formation of the final sample through the different exclusion steps is presented in  . \\n  \\nA flowchart depicting the steps leading to our final sample size of 121. The region of interest (ROI) exclusions are presented in  . \\n  \\n\\n### The Study Visits \\n  \\nAll MRI scans were performed for research purposes by the research staff (one research nurse, four Ph.D. students, and two MR technologists). Before the visit, each family was personally contacted and recruited via telephone calls by a research staff member. The scan preparations started with the recruitment and at home training. We introduced the image acquisition process to the parents and advised them to explain the process to their children and confirm child assent before the follow up phone call that was used to confirm the willingness to participate. Thereafter, we advised the parents to use at home familiarization methods such as showing a video describing the visit, playing audio of scanner sounds, encouraging the child to lie still like a statue (“statue game”), and practicing with a homemade mock scanner, e.g., a cardboard box with a hole to view a movie through. The visit was marketed to the participants as a “space adventure,” which is in principle similar to the previously described “submarine protocol” ( ) but the child was allowed to come up with other settings as well. A member of the research staff made a home visit before the scan to deliver earplugs and headphones, to give more detailed information about the visit, and to answer any remaining questions. An added benefit of the home visit was the chance to meet the participating child and that way start the familiarization with the research staff. \\n\\nAt the start of the visit, we familiarized the participant with the research team (research nurse and a medically trained Ph.D. student) and acquired written informed consent from both parents. This first portion of the visit included a practice session using a non-commercial mock scanner consisting of a toy tunnel and a homemade wooden head coil. Inexpensive non-commercial mock scanners have been shown to be as effective as commercial ones ( ). The participants brought at least one of their toys that would undergo a mock scan (e.g., an MRI compatible stuffed animal they could also bring with them into the real scanner). The researcher played scanner sounds on their cell phone during the mock scan and the child could take pictures of the toy lying still and of the toy being moved by the researcher to demonstrate the importance of lying still during the scan. Communication during the scan was practiced. Overall, these preparations at the scan site were highly variable as we did our best to accommodate to befit the child characteristics (e.g., taking into account the physical activity and anxiety) in cooperation with the family. Finally, we served a light meal of the participant’s choice before the scan. \\n\\nThe participants were scanned awake or during natural sleep. One member of the research staff and parent(s) stayed in the scanner room throughout the whole scan. During the scan, participants wore earplugs and headphones. Through the headphones, they were able to listen to the movie or TV show of their choice while watching it with the help of mirrors fitted into the head coil (the TV was located at the foot of the bed of the scanner). Some foam padding was applied to help the head stay still and assure comfortable position. Participants were given a “signal ball” to throw in case they needed or wanted to stop or pause the scan (e.g., to visit the toilet). If the research staff member noticed movement, they gently reminded the participant to stay still by lightly touching their foot. This method of communication was agreed on earlier in the visit and was planned to convey a clear signal of presence while minimizing the tactile stimulation. Many of the methods used to reduce anxiety and motion during the scan have been described in earlier studies ( ;  ). \\n\\nAll images were viewed by one neuroradiologist (RP) who then consulted a pediatric neurologist (TL) when necessary. There were four (out of 146, 2.7%) cases with an incidental finding that required consultation. All four cases initially entered the FreeSurfer processing pipeline and three were included in the final ROI based analyses. The protocol with incidental findings has been described in our earlier work ( ), and a separate report of their incidence is in preparation for the eventual full data set. \\n\\n\\n### Magnetic Resonance Imaging Data Acquisition \\n  \\nParticipants were scanned using a Siemens Magnetom Skyra fit 3T with a 20-element head/neck matrix coil. We used Generalized Autocalibrating Partially Parallel Acquisition (GRAPPA) technique to accelerate image acquisition [parallel acquisition technique (PAT) factor of 2 was used]. The MRI data was acquired as a part of max. 60-min scan protocol. The scans included a high resolution T1 magnetization prepared rapid gradient echo (MPRAGE), a T2 turbo spin echo (TSE), a 7-min resting state functional MRI, and a 96-direction single shell (b = 1,000 s/mm ) diffusion tensor imaging (DTI) sequence ( ) as well as a 31-direction with b = 650 s/mm  and a 80-direction with b = 2,000 s/mm . For the purposes of the current study, we acquired high resolution T1-weighted images with the following sequence parameters: repetition time (TR) = 1,900 ms, echo time (TE) = 3.26 ms, inversion time (TI) = 900 ms, flip angle = 9 degrees, voxel size = 1.0 × 1.0 × 1.0 mm , and field of view (FOV) 256 × 256 mm . The scans were planned as per recommendations of the FreeSurfer developers. \\n\\n\\n### Data Processing \\n  \\n#### FreeSurfer \\n  \\nCortical reconstruction and volumetric segmentation for all 134 images were performed with the FreeSurfer software suite, version 6.0.0.  We selected the T1 image with the least motion artifact (in case there were several attempts due to visible motion during scan) and then applied the “recon-all” processing stream with default parameters. It begins with transformation to Talaraich space, intensity inhomogeneity correction, bias field correction ( ), and skull-stripping ( ). Thereafter, WM is separated from GM and other tissues and the volume within the created WM–GM boundary is filled. After this, the surface is tessellated and smoothed. After these preprocessing steps are completed, the surface is inflated ( ) and registered to a spherical atlas. This method adapts to the folding pattern of each individual brain, utilizing consistent folding patterns such as the central sulcus and the sylvian fissure as landmarks, allowing for high localization accuracy ( ). FreeSurfer uses probabilistic approach based on Markov random fields for automated labeling of brain regions. Cortical thickness is calculated as the average distance between the WM–GM boundary and the pial surface on the tessellated surface ( ). The cortical thickness measurement technique has been validated against post-mortem histological ( ) and manual measurements ( ;  ). \\n\\n\\n#### FreeSurfer Manual Edits and the Freeview Quality Control Protocol \\n  \\nWe used Freeview to view and edit the images using the standard command recommended by the FreeSurfer instructions with the addition of the Desikan–Killiany atlas that allowed us to correctly identify the ROIs where errors were found. Images with excess motion artifact or large unsegmented regions (extending over multiple gyri, examples provided in  ) were excluded. There were 13 participants that were excluded due to erroneous segmentation. The images that passed the initial quality check were then manually edited (the time required for manual editing ranged from 45 min in high quality images to over 3 h in images with a lot of artifact, taking approximately 2 h on average). All images were examined in all three directions one hemisphere at a time and the edits were made for every slice regardless of the ROI in question. Subsequently, we ran the automated segmentation process again as suggested by FreeSurfer instructions. The images were then inspected again for errors, and the ROIs with errors that affect WM–GM or pial borders were excluded in the Freeview quality control protocol. The Freeview protocol presented in this study was adapted locally for the FinnBrain Neuroimaging Lab as a method to assess errors in a slice-by-slice view from the official quality control procedure provided in the FreeSurfer instructions.  We also provide a practical application manual in   ( , pages 3–9, FreeSurfer editing) that we give to new researchers when they start practicing the FinnBrain manual editing and quality control protocol. \\n\\n##### Errors in Borders \\n  \\nThe automatically segmented images generated by FreeSurfer software suite were visually inspected and the found errors were either manually corrected or the ROI with the error was simply excluded depending on the type of error. Excess parts of the skull were removed where the pial border was affected by them ( ). Arteries were removed to avoid segmentation errors between arteries and WM (especially relevant for anterior temporal areas and the insulae). This was done by setting the eraser to only delete voxels with intensity between 130 and 190 in the brainmask volume. The arteries were removed throughout the image with no regard to whether they caused issues in the segmentation on that specific slice. An example can be seen in  . In cases where an error appeared in a junction between ROIs, all adjoining ROIs were excluded. \\n  \\nA presentation of some common errors and fixes related to the pial border and non-brain tissues.   (A)   Demonstrates how skull fragments can cause errors in pial border (yellow circles).   (B)   Presents the same subject with skull fragments removed. In panel   (C)  , arteries were removed (green circle). We removed voxels with an intensity between 130 and 190, and therefore some parts of arteries were not removed (yellow circle).   (C)   Also demonstrates the challenges with artifact, meninges, and the pial border. In some areas, the pial border may extend into the meninges (yellow arrows). Meanwhile, at the other end of the same gyrus, the border may seem correct (green arrows). It is difficult to fix these errors manually. Additionally, the visible motion artifact adds further challenges to manual edits of the pial border. In panel   (D)  , the pial border cuts through a gyrus. \\n  \\nOne typical error was that parts of the superior sagittal sinus (SSS) were included within the pial border. We stopped editing the SSS after an interim assessment as it was an arduous task with little effect on final results. All information regarding SSS edits is presented in   ( , pages 10–14, Superior sagittal sinus). \\n\\nIn addition, there were errors that could not be fixed easily. In some cases, the pial border may cut through the cortex (  shows an error in the left rostral middle frontal region). In these cases, the remaining GM mask is too small, and this error cannot be easily fixed in Freeview. Manual segmentation of a T1 image is labor intensive and hard to conduct reliably with 1 mm  resolution even when the edits would cover small areas. Moreover, the FreeSurfer instructions do not recommend this approach. Additionally, the WM mask edits recommended in FreeSurfer instructions would not fix all cases where the cortical segmentation is too thin, as the WM mask often seemed adequate in these areas (an example presented in  ). Therefore, we simply had to exclude the ROI(s) in question. \\n\\nSmall errors of the WM–GM border were prevalent throughout the brain. The corrections were made by erasing excess WM mask. This process is demonstrated in  . WM–GM border was inspected after the manual edits. A continuous error of at least ten slices in the coronal view led to exclusion of all the ROIs directly impacted by the error. Furthermore, ubiquitous errors in the WM–GM border, as markers of motion artifact, led to exclusion of the whole brain (as in  ). \\n  \\nA demonstration of our white matter (WM) mask editing protocol.   (A)   Shows a typical error in the border between white and gray matter (WM–GM border), where it extends too close to the pial border. Errors such as this are searched for in the “brainmask” volume   (A,D)  .   (B)   Shows the same error in “wm” volume with “Jet” colormap   (B,C)  .   (C)   Shows how we fixed these errors by erasing the erroneous WM mask (blue voxels).   (D)   Shows the final result after the second recon-all. \\n    \\nTwo examples of excluded brain images.   (A)   Shows “waves” throughout the image, marking motion artifact.   (B)   Shows the same subject as in panel   (A)   in a coronal view and borders visible. This image shows motion artifact related errors in the border between white and gray matter (WM–GM border), denoted by the yellow circle. Additionally, there is potential unsegmented area due to motion artifact (green circle) and poor contrast between WM and GM (white circle).   (C,D)   Show another excluded subject. The motion artifact in panel   (C)   is not as pronounced as in panel   (A)  . However,   (D)   still shows some typical errors for images with much artifact. There is a clear pial error (white arrow). Additionally, the yellow arrows show typical cases, where the “ringing” causes the WM mask to “widen” where the actual WM meets the ringing motion artifact. \\n  \\nFurthermore, there are some error types that cannot be easily fixed but also do not warrant exclusion. One such problem is that the pial border often extends into the cerebrospinal fluid or meninges around the brain ( ). The issue with this type of error is that sometimes the real border between GM and the surrounding meninges cannot be denoted visually and therefore the error cannot be reliably fixed. This problem is further complicated by the fact that motion artifact may mimic the border between GM and meninges making the visual quality control challenging (  and  ). In addition to motion, fat shift can also cause this type of artifact. The amount of fat shift in images is dependent on the imaging protocol, more specifically the bandwidth of the acquisition. \\n\\nThere were some minor incongruities in multiple images. A common example can be seen in  , where there seems to be a potential error in the pial border. Areas like this look normal in other planes. A less common example is shown in  , where there is an apparent discontinuation in the WM–GM border. Similarly, there was no discontinuation in other planes. Both these minor incongruities were considered partial volume effects related to the presentation of a 3D surface in 2D slices. Therefore, both cases were included. \\n\\n\\n##### Errors in Cortical Labeling \\n  \\nA common issue was the presence of WM hypointensities in the segmented images. They sometimes erroneously appeared in the cortex. These errors were typically small and did not cause errors in pial or WM–GM borders ( ), and in those cases did not require exclusion. The hypointensities themselves were rarely successfully fixed by editing the WM mask and therefore were left unedited unless they caused errors in the GM–WM border. In those cases, removing the WM mask fairly often fixed the error in the border, although frequently the incorrect hypointensity label still remained in the WM segmentation. We tried to fix the errors in the WM–GM border and when unsuccessful, we simply excluded the ROI in question from analyses ( ). Of note, these errors can only be seen with the anatomical labels as overlays, unless they affect the WM–GM border. \\n  \\n (A,B)   Show a white matter (WM) hypointensity that affects the border between white and gray matter (WM–GM border), denoted by a yellow circle.   (C,D)   Show how the posterior part of the lateral ventricle causes distortion to the WM–GM border (yellow circle). If the error was not successfully fixed, all regions adjoining the error were excluded. \\n  \\nOne typical error occurred at the posterior end of the lateral ventricles, where it may cause segmentation errors in the adjacent cortical regions, typically the precuneus and the lingual gyrus. These regions were excluded from analyses when there was a distortion in the GM–WM border ( ), and included when there was no distortion in the border ( ). Unfortunately, hypointensities often appeared in ROI junctions, leading to exclusion of multiple regions due to one error ( ). Similar errors were seen in the ENIGMA protocol as well ( ). \\n\\n\\n##### Errors in Subcortical Labeling \\n  \\nPutamen was often mislabeled by FreeSurfer in our sample. Errors were addressed by adding control points, but the edits were largely unsuccessful. Consequently, we are currently working on separately validating subcortical segmentation procedures for our data ( ). All information regarding the subcortical labeling is presented in   ( , pages 15–16, Subcortex). \\n\\n\\n\\n#### ENIGMA Quality Control Protocol \\n  \\nAfter the quality control that entailed manual edits, we conducted a quality check with the ENIGMA Cortical Quality Control Protocol 2.0 (April 2017).  Therein, the FreeSurfer cortical surface measures were extracted and screened for statistical outliers using R  and visualized via Matlab (Mathworks) and bash scripts. Visual representations of the external 3D surface and internal 2D slices were generated and visually inspected according to the instructions provided by ENIGMA in   (at the time of writing). The ENIGMA Cortical quality check instructions remark how certain areas have a lot of anatomical variation and therefore they note the possibility to be more or less stringent in their quality control. Considering this and the fact that the example images provided in the ENIGMA instructions are limited in number and as such cannot show every variation, we deemed necessary to describe how we implemented these instructions in our sample. \\n\\n##### The External View \\n  \\nWe started by viewing the external image. The pre- and postcentral gyri were assessed for meninge overestimations, which can manifest as “spikes” ( ) or flat areas ( ). These error types were rare in our sample. These cases were excluded as instructed. \\n\\nThe supramarginal gyrus has a lot of anatomical variability and when quality checking it, we decided to be lenient as suggested by the ENIGMA instructions. We only excluded cases where the border between supramarginal and inferior parietal regions cuts through a gyrus, leading to discontinuous segments in one of the regions ( ). In some rare cases, this type of error also happened with the postcentral gyrus ( ), and these cases were also excluded. Similarly, in cases with supramarginal gyrus overestimation into the superior temporal gyrus, we only excluded clear errors (examples presented in  ). \\n  \\n (A)   Shows an error (yellow circle) where the inferior parietal area (purple) cuts through a whole gyrus in the supramarginal region (green). This area has a lot of variation and only clear errors led to exclusion in our ENIGMA quality control protocol.   (B)   Shows insula overestimation in the midline (green circle). Furthermore, the poor image quality can be seen the areas adjacent to the base of the skull, such as parahippocampal (green area denoted by a red arrow) and entorhinal (red area denoted be a white arrow). Additionally, there is an error in the border between superior frontal and caudal anterior cingulate. This border should follow the sulcal line. The rostral anterior cingulate was not considered erroneous in these cases. \\n  \\nOne commonly seen error is insula overestimation into the midline ( ). In these cases, we exclude insula and the region(s) adjacent to it in the midline (e.g., the medial orbitofrontal region in the case of  ). \\n\\nThe border between the superior frontal region and the cingulate cortex (  and  ) is one typical place for errors. A prominent paracingulate sulcus, that is more common on the left than on the right hemisphere, may cause underestimation of the cingulate cortex and consequently overestimation of the superior frontal region. This was typically seen on the left caudal anterior cingulate ( ), where we excluded the cases where the border did not follow sulcal lines anteriorly (as was demonstrated in the image examples in the instructions). In rare cases the border between posterior cingulate and superior frontal region was affected ( ), and these were also excluded. \\n\\nThe pericalcarine region was overestimated in some cases. According to the instructions cases where the segmentation is confined to the calcarine sulcus should be accepted. Therefore, we excluded cases where the pericalcarine region extended over a whole gyrus into the lingual gyrus or the cuneus. An example can be seen in  . \\n\\nCases of superior parietal overestimation were excluded as instructed. These errors were rare in our sample. Similarly, errors in the banks of the superior temporal sulcus were excluded as instructed. \\n\\nThe border between the middle and inferior temporal gyrus was not assessed, as the instructions suggested that most irregularities seen there are normal variants or relate to the viewing angle. \\n\\nSimilarly, we did not quality check the entorhinal/parahippocampal regions in the external view, as there is a lot of variation in the area. The ENIGMA instructions describe underestimations in 70–80% of cases. Furthermore, this region looks poor in practically all images (e.g., in  ) as do all the regions adjacent to the base of the skull and therefore, in our opinion, the quality assessment in those regions requires additional procedures, that are beyond the scope of the current study, to confirm their usability in statistical analyses. \\n\\n\\n##### The Internal View \\n  \\nIn the internal view, regions with unsegmented GM were excluded. These errors often reflect WM hypointensities seen in Freeview ( ). Interestingly, even quite large hypointensities do not necessarily equate to errors in the borders set by FreeSurfer and therefore do not always have an adverse effect on CT calculations. \\n\\nTemporal pole underestimations were sometimes seen. However, the cases were rarely as clear as presented in the instructions. Therefore, we had to use both coronal and axial views to assess the situation and make exclusions when both views supported an error in segmentation. \\n\\nOne of the errors commonly seen in our sample was the erroneous pial surface delineation in the lateral parts of the brain. This was particularly prevalent in the middle temporal gyri ( ). Notably, it is possible to attempt fixing these types of topological errors, e.g., by using control points or brainmask edits. Some previous studies (e.g.,  ) have done this. They reported average editing time of 9, 5 h, approximately quadruple our editing time, and concluded that the edits did not affect conclusions. Therefore, this type of edit was omitted as too time-consuming and challenging compared to the expected effect on results. The ROIs affected by these errors were excluded from analyses. This error was assessed from 2D slices, wherein what seems to be an error may be caused by partial volume effects. For example, in  , there seems to be a possible error on the right middle temporal region. If we look at the same image in Freeview, the same position seems to be segmented normally, especially when confirmed in the axial view ( ). Consequently, we only made exclusion when clear errors were seen in two adjacent slices. Particularly clear example of this can be seen in  , where the WM extends outside the segmentation. The error is also visible in the external view, where these regions do not appear as smooth as normally ( ), however the decisions to exclude a ROI were always made based on the internal view. This kind of error was significantly harder to recognize in Freeview and represents the most striking difference in results between the ENIGMA and Freeview quality control protocols. \\n  \\nThere are some visible errors in the lateral parts of the image (arrows). An especially clear error is denoted by the red circle, where some white matter is seen outside the cortical segmentation. \\n  \\n\\n##### Statistical Outliers \\n  \\nAfter the systematic viewing of all the problem regions, we inspected the statistical outliers. This rarely led to new exclusions, as many of the statistical outliers were among the excluded subjects or the outliers were ROIs where the instructions did not give any tools to assess whether they were correct. Therefore, we had to simply double check the internal view to rule out segmentation errors. \\n\\n\\n##### Enhancing Neuro Imaging Genetics Through Meta Analysis Exclusion Differences Between Edited and Unedited Images \\n  \\nWe performed the full ENIGMA quality control protocol for all edited images that were included in the ROI based analyses (  n   = 121). To assess how manual edits affect the number of excluded regions, we also performed the ENIGMA quality control protocol on a half sample (  n   = 61) of unedited images. In borderline cases (mostly regarding the borders between the supramarginal and superior temporal gyri as well as between the caudal anterior cingulate and superior frontal gyri) we consulted the ENIGMA quality control protocol of the edited images, to make the same ruling if the error was similar. Likewise, in the cases where the edited image passed the internal or external view without any ROI exclusions, but did not pass in the unedited version, the images were directly compared to each other to ensure the reason for not passing is an objective difference, as opposed to a human error or a different ruling in a borderline case. \\n\\n\\n\\n#### Exclusions \\n  \\nWe decided to use a dichotomous rating scale: pass or fail. The amount of motion artifact (marked by “concentric rings” or “waves”) and the clarity of the WM–GM border were assessed from the original T1 image. In borderline cases, we ran the standard recon-all and made new assessment based on the segmented image. Massive segmentation errors such as large missing areas or ubiquitous errors in WM–GM border were reasons for exclusion. Additionally, ENIGMA exclusion criteria were implemented as instructed. In some borderline cases, another expert rater assessed the image quality and agreement was reached to either include or exclude the image. Some images that were considered for inclusion but excluded after the first recon-all can be seen in  . These images had significantly more artifact than other images in our sample, although arguably they could have been included since the amount of artifact could be described as “moderate.” However, we decided to implement strict exclusion criteria to ensure high quality of data. \\n\\n\\n#### Alternate Processing: Optional Registration Flags in FreeSurfer \\n  \\nWe compared the FreeSurfer default recon all to recon-all with the “-mprage” and “-schwartzya3t-atlas” optional flags. All information regarding optional flags analyses is presented in   ( , pages 17–18, Optional flags). \\n\\n\\n#### Alternate Processing: CAT12 \\n  \\nA previous study conducted in the elderly demonstrated good agreement between FreeSurfer and CAT12 estimates of CT (  R   = 0.83), although CAT12 produced systematically higher values than FreeSurfer ( ). Therefore, we decided to explore the agreement between the two software in a pediatric population. All information regarding CAT12 analyses is presented in   ( , pages 19–25, CAT12). \\n\\n\\n\\n### Alternate Quality Control: Qoala-T \\n  \\nQoala-T is a supervised learning tool for quality control of automated labeling processed in FreeSurfer, and it is particularly intended for use in analysis of pediatric datasets ( ). We compared Qoala-T scores from all 134 participants that entered the FreeSurfer segmentation protocol, and the results are reported in   ( , pages 26–29, Qoala-T). \\n\\n\\n### Statistics \\n  \\nStatistical analyses were conducted using the IBM SPSS Statistics for Windows, version 25.0 (IBM Corp., Armonk, NY, United States). The ROI data was confirmed to be normally distributed using JMP Pro 15 (SAS Institute Inc., Cary, NC, United States) based on visual assessment and the similarity of mean and median values. \\n\\nTo compare the differences between the included (the participants that were included in ROI based analyses,   n   = 121) and excluded (all participants that lacked usable T1 data,   n   = 25) groups, we performed independent samples   t  -tests for age from birth at scan, gestational age at scan, gestational age at birth, birthweight, maternal age at term, and maternal body mass index (BMI) before pregnancy. In addition, we conducted Chi-Square tests for child gender, maternal education level (three classes: 1 = Upper secondary school or vocational school or lower, 2 = University of applied sciences, and 3 = University), maternal monthly income estimate after taxes (in euros, four classes: 1 = 1,500 or less, 2 = 1,501–2,500, 3 = 2,501–3,500, and 4 = 3,501 or more), maternal alcohol use during pregnancy (1 = yes, continued to some degree after learning about the pregnancy, 2 = yes, stopped after learning about the pregnancy, and 3 = no), maternal tobacco smoking during pregnancy (1 = yes, continued to some degree after learning about the pregnancy, 2 = yes, stopped after learning about the pregnancy, and 3 = no), maternal history of disease (allergies, depression, asthma, anxiety disorder, eating disorder, chronic urinary tract infection, autoimmune disorder, hypercholesterolemia, and hypertension), and maternal medication use at gestational week 14 (non-steroidal anti-inflammatory drugs, thyroxin, selective serotonin reuptake inhibitor [SSRI] or serotonin–norepinephrine reuptake inhibitor [SNRI], and corticosteroids), or at gestational week 34 (thyroxin, SSRI or SNRI, corticosteroids, and blood pressure medications). The categories in history of disease and medication during pregnancy were only included in statistical analyses, when there were at least four participants that had history of the disease or used the medication (to limit the chance of false positives). \\n\\nTo compare the exclusion rates between Freeview and ENIGMA quality control protocols, as well as between ENIGMA quality control protocols of edited and unedited images, we conducted Chi-Square tests (among all datapoints, single ROIs, and internal/external view passes in ENIGMA). \\n\\nThe inclusion criterion for the ROI based comparisons was passing the ENIGMA quality control protocol. To compare edited FreeSurfer to unedited FreeSurfer, we conducted a paired samples   t  -test. We calculated the absolute values of the change in CT between unedited and edited images for each ROI separately using the following formula: (C /C ) * 100%, where C  is the absolute value of the difference in mean CT between edited and unedited images and C  is the mean CT in the unedited images. Furthermore, we conducted a paired samples   t  -test with the mean CT values from all ROIs to measure the change between edited and unedited images. The same analyses were performed for WM SA and GM volume. \\n\\nTo assess the effects of manual editing and quality control on group comparison and brain structural asymmetry results, we conducted independent samples   t  -tests for sex differences in CT, SA, and volume measurements between a sample without quality control (  n   = 121 for every ROI) and the quality-controlled sample (maximum   n   = 121, where number of included ROIs varies). Using these same samples, we also conducted paired samples   t  -tests for the 34 ROIs in both hemispheres to examine structural asymmetry.  ,   output was created using JASP 0.16.1 ( ). \\n\\nAll significances were calculated 2-tailed (α = 0.05). To adjust for multiple comparisons in ROI-based analyses, we conducted the Bonferroni correction by setting the   p   value to 0.05 divided by the number of comparisons (=the number of ROIs = 68), resulting in   p   = 0.000735. We notify that the   p   value cut off for the current study is somewhat arbitrary and thus we also report the raw   p   values in the tables. \\n\\n\\n'\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d12784-5fb0-4f1c-8845-115130668f39",
   "metadata": {},
   "source": [
    "### Embed all documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e03363f3-9d81-4f95-b92d-8fff42ef8b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "openai.api_key = open('/home/zorro/.keys/open_ai.key').read().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82653681-200e-4df4-a185-69d4376dbea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# pickle.dump(single_group_embeddings, open('data/single_group_embeddings.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed160b44-d6ec-46db-bbd2-166d31dc0d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_group_embeddings = pickle.load(open('data/single_group_embeddings.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b423b9e-85ab-429e-957a-d8dc59fe007e",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_group_embeddings = pd.DataFrame(single_group_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d2d6e91-3f51-4e95-8374-11b794854d4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>section_name</th>\n",
       "      <th>content</th>\n",
       "      <th>start_char</th>\n",
       "      <th>end_char</th>\n",
       "      <th>embedding</th>\n",
       "      <th>pmcid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Authors</td>\n",
       "      <td>Pulli, Elmo P. and Silver, Eero and Kumpulaine...</td>\n",
       "      <td>0</td>\n",
       "      <td>323</td>\n",
       "      <td>[-0.005361288785934448, -0.015115763060748577,...</td>\n",
       "      <td>9108497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Title</td>\n",
       "      <td>\\n# Title\\n\\nFeasibility of FreeSurfer Process...</td>\n",
       "      <td>323</td>\n",
       "      <td>468</td>\n",
       "      <td>[-0.011751627549529076, 0.026484699919819832, ...</td>\n",
       "      <td>9108497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Keywords</td>\n",
       "      <td>\\n# Keywords\\n\\nbrain\\nchild\\nneuroimaging\\nbr...</td>\n",
       "      <td>468</td>\n",
       "      <td>563</td>\n",
       "      <td>[-0.02721841260790825, 0.02183225192129612, 0....</td>\n",
       "      <td>9108497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abstract</td>\n",
       "      <td>\\n# Abstract\\n \\nPediatric neuroimaging is a q...</td>\n",
       "      <td>563</td>\n",
       "      <td>2381</td>\n",
       "      <td>[-0.0069894008338451385, 0.03050420992076397, ...</td>\n",
       "      <td>9108497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Body</td>\n",
       "      <td>\\n# Body\\n \\n## Introduction \\n  \\nThere are m...</td>\n",
       "      <td>2381</td>\n",
       "      <td>5253</td>\n",
       "      <td>[-0.0003534696879796684, 0.024464335292577744,...</td>\n",
       "      <td>9108497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1744</th>\n",
       "      <td>Body</td>\n",
       "      <td>\\n## Data Availability Statement \\n  \\nThe raw...</td>\n",
       "      <td>31764</td>\n",
       "      <td>31956</td>\n",
       "      <td>[-0.016607334837317467, -0.02181965485215187, ...</td>\n",
       "      <td>6908505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1745</th>\n",
       "      <td>Body</td>\n",
       "      <td>\\n## Ethics Statement \\n  \\nThe studies involv...</td>\n",
       "      <td>31956</td>\n",
       "      <td>32200</td>\n",
       "      <td>[-0.008219190873205662, -0.012068435549736023,...</td>\n",
       "      <td>6908505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1746</th>\n",
       "      <td>Body</td>\n",
       "      <td>\\n## Author Contributions \\n  \\nKM designed th...</td>\n",
       "      <td>32200</td>\n",
       "      <td>32513</td>\n",
       "      <td>[-0.0033632966224104166, 0.008040985092520714,...</td>\n",
       "      <td>6908505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1747</th>\n",
       "      <td>Body</td>\n",
       "      <td>\\n## Funding \\n  \\nThe study was based on two ...</td>\n",
       "      <td>32513</td>\n",
       "      <td>32823</td>\n",
       "      <td>[0.0009335727663710713, -0.024999098852276802,...</td>\n",
       "      <td>6908505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1748</th>\n",
       "      <td>Body</td>\n",
       "      <td>\\n## Conflict of Interest \\n  \\nKM declares ha...</td>\n",
       "      <td>32823</td>\n",
       "      <td>33295</td>\n",
       "      <td>[0.0014716944424435496, -0.01084829866886139, ...</td>\n",
       "      <td>6908505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1749 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     section_name                                            content  \\\n",
       "0         Authors  Pulli, Elmo P. and Silver, Eero and Kumpulaine...   \n",
       "1           Title  \\n# Title\\n\\nFeasibility of FreeSurfer Process...   \n",
       "2        Keywords  \\n# Keywords\\n\\nbrain\\nchild\\nneuroimaging\\nbr...   \n",
       "3        Abstract  \\n# Abstract\\n \\nPediatric neuroimaging is a q...   \n",
       "4            Body  \\n# Body\\n \\n## Introduction \\n  \\nThere are m...   \n",
       "...           ...                                                ...   \n",
       "1744         Body  \\n## Data Availability Statement \\n  \\nThe raw...   \n",
       "1745         Body  \\n## Ethics Statement \\n  \\nThe studies involv...   \n",
       "1746         Body  \\n## Author Contributions \\n  \\nKM designed th...   \n",
       "1747         Body  \\n## Funding \\n  \\nThe study was based on two ...   \n",
       "1748         Body  \\n## Conflict of Interest \\n  \\nKM declares ha...   \n",
       "\n",
       "      start_char  end_char                                          embedding  \\\n",
       "0              0       323  [-0.005361288785934448, -0.015115763060748577,...   \n",
       "1            323       468  [-0.011751627549529076, 0.026484699919819832, ...   \n",
       "2            468       563  [-0.02721841260790825, 0.02183225192129612, 0....   \n",
       "3            563      2381  [-0.0069894008338451385, 0.03050420992076397, ...   \n",
       "4           2381      5253  [-0.0003534696879796684, 0.024464335292577744,...   \n",
       "...          ...       ...                                                ...   \n",
       "1744       31764     31956  [-0.016607334837317467, -0.02181965485215187, ...   \n",
       "1745       31956     32200  [-0.008219190873205662, -0.012068435549736023,...   \n",
       "1746       32200     32513  [-0.0033632966224104166, 0.008040985092520714,...   \n",
       "1747       32513     32823  [0.0009335727663710713, -0.024999098852276802,...   \n",
       "1748       32823     33295  [0.0014716944424435496, -0.01084829866886139, ...   \n",
       "\n",
       "        pmcid  \n",
       "0     9108497  \n",
       "1     9108497  \n",
       "2     9108497  \n",
       "3     9108497  \n",
       "4     9108497  \n",
       "...       ...  \n",
       "1744  6908505  \n",
       "1745  6908505  \n",
       "1746  6908505  \n",
       "1747  6908505  \n",
       "1748  6908505  \n",
       "\n",
       "[1749 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_group_embeddings.i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e2fd934a-1a1d-49d7-b071-5ada5c02ed49",
   "metadata": {},
   "outputs": [],
   "source": [
    "_PARTICIPANTS_SECTIONS = (\n",
    "    r\"#+ .*(?:participants?|subjects?|patients|population).*\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966239b6-86f1-4118-9ec9-393426890a86",
   "metadata": {},
   "source": [
    "### Test query across all documents\n",
    "\n",
    "Given a query, see what the average rank for the chunk matching the human annotation is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8d4b024-47c7-4b63-b9b0-056d86bb61e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "def get_matching_chunks(ranks_df, annotation_df):\n",
    "    \"\"\" Select the chunks that contains the original annotation \"\"\"\n",
    "    matches = []\n",
    "    for _, row in annotation_df.iterrows():\n",
    "        for ix, start_char in enumerate(row['start_char']):\n",
    "            end_char = row['end_char'][ix]\n",
    "            m = ranks_df[\n",
    "                (ranks_df['pmcid'] == row['pmcid']) & \\\n",
    "                (ranks_df['start_char'] <= start_char) & (ranks_df['end_char'] >= end_char)]\n",
    "            if not m.empty:\n",
    "                matches.append(m)\n",
    "                break\n",
    "    \n",
    "    return pd.concat(matches)\n",
    "\n",
    "def get_chunk_query_distance(embeddings_df, query):\n",
    "    # For every document, get distance and rank between query and embeddings\n",
    "    distances, ranks = zip(*[\n",
    "        query_embeddings(sub_df['embedding'].tolist(), query) \n",
    "        for pmcid, sub_df in embeddings_df.groupby('pmcid', sort=False)\n",
    "    ])\n",
    "\n",
    "    # Combine with meta-data into a df\n",
    "    ranks_df = embeddings_df[['pmcid', 'content', 'start_char', 'end_char']].copy()\n",
    "    ranks_df['distance'] = np.concatenate(distances)\n",
    "    ranks_df['rank'] = np.concatenate(ranks)\n",
    "\n",
    "    return ranks_df\n",
    "    \n",
    "def evaluate_query_across_docs(embeddings_df, annotations_df, query):\n",
    "    ranks_df = get_chunk_query_distance(embeddings_df, query)\n",
    "    \n",
    "    mc = get_matching_chunks(ranks_df, annotations_df)\n",
    "\n",
    "    print(\n",
    "        f\"Query: '{query}' \\nMean rank: {mc['rank'].mean():.2f},\\\n",
    "        top 1 %: {(mc['rank'] == 0).mean():.2f}, \\\n",
    "        top 3 %: {(mc['rank'] <= 3).mean():.2f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "358bc87c-6506-44d7-a11a-ca1cea20431d",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = ['ljskfdklsjdfk', 'Methods section', 'Number of participants',\n",
    "           'The number of subjects or participants that were involved in the study or underwent MRI',\n",
    "           'How many participants or subjects were recruited for this study?',\n",
    "           'How many participants were recruited for this study?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "783a61ba-eb13-4fa5-a3f7-ea6bed0f40cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for q in queries:\n",
    "    evaluate_query_across_docs(single_group_embeddings, single_group, q)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f3cf52-cb72-4e8e-a6a6-3c08435b0f5b",
   "metadata": {},
   "source": [
    "### Try only on Body\n",
    "\n",
    "Looks like *for some studies* Jerome's annotations were only in the Body of the study, so it would be fair to exclude any embeddings not on the Body of the paper. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7ddc75c7-9cc9-4143-aaa3-b43964ca45bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_group_embeddings_body = single_group_embeddings[single_group_embeddings.section_name == 'Body'].reset_index().drop(columns='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea1ac069-f189-4c13-b5fe-7a5d20dc4f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for q in queries:\n",
    "#     evaluate_query_across_docs(single_group_embeddings_body, single_group, q)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c4eb45-b13b-4288-abd6-3479fb2b03dd",
   "metadata": {},
   "source": [
    "### Compare to heuristic approach (looking for headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a26b002-83d4-40c7-86f6-59b84edac45b",
   "metadata": {},
   "source": [
    "# Extract Sample Size from relevant secton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "be06f7f4-59ba-481b-82d7-b7bacdd659a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from extract import extract_from_multiple\n",
    "from templates import ZERO_SHOT_SAMPLE_SIZE_FUNCTION\n",
    "\n",
    "def extract_sample_size_full_text(embeddings_df, annotations_df, query, template, num_workers=3, model_name='gpt-3.5-turbo'):\n",
    "    ranks_df = get_chunk_query_distance(embeddings_df, query)\n",
    "    mc = get_matching_chunks(ranks_df, annotations_df).rename(columns={'rank': 'matching_rank'})[['pmcid', 'matching_rank']]\n",
    "    \n",
    "    ranks_df = pd.merge(ranks_df, mc, on='pmcid')\n",
    "    ranks_df['is_matching_chunk'] = ranks_df['rank'] == ranks_df['matching_rank']\n",
    "\n",
    "    # Subset to only include top ranked chunks\n",
    "    ranks_df = ranks_df[ranks_df['rank'] == 0]\n",
    "\n",
    "    # For every chunk, apply template\n",
    "    predictions = extract_from_multiple(\n",
    "        ranks_df.content.to_list(), \n",
    "        **template, \n",
    "        num_workers=num_workers,\n",
    "        model_name=model_name\n",
    "    )\n",
    "\n",
    "    predictions = pd.DataFrame(predictions)\n",
    "\n",
    "    predictions['is_matching_chunk'] = ranks_df['is_matching_chunk'].tolist()\n",
    "    predictions['pmcid'] = ranks_df['pmcid'].tolist()\n",
    "    predictions['content'] =  ranks_df['content'].tolist()\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae9ff6b-15f0-403e-835b-d04c18c47dec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9c9ccc6b-7125-4e0e-aae1-f6546e5aa3f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 69/69 [00:18<00:00,  3.66it/s]\n"
     ]
    }
   ],
   "source": [
    "full_text_demo = extract_sample_size_full_text(\n",
    "    single_group_embeddings_body, single_group,\n",
    "    'How many participants were recruited for this study?', \n",
    "    ZERO_SHOT_SAMPLE_SIZE_FUNCTION\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32feaaa3-10da-42de-bd67-cf760c291a47",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f0cc9ee5-e8ed-4ab9-9796-306c21780933",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_within_percentage(num1, num2, percentage=10):\n",
    "    if int(num1) == int(num2):\n",
    "        return True\n",
    "    if abs(int(num1) - int(num2)) / int(num1) <= percentage / 100:\n",
    "        return True\n",
    "    return False\n",
    "    \n",
    "def _print_evaluation(predictions_df, annotations_df):\n",
    "\n",
    "    # Combine annotations with predicted values\n",
    "    eval_df = annotations_df.reset_index()[['count', 'pmcid']].rename(columns={'count': 'annot_count'})\n",
    "    predictions_df = pd.merge(predictions_df, eval_df)\n",
    "    predictions_df['correct'] = predictions_df['count'] == predictions_df['annot_count']\n",
    "    \n",
    "    wrong_chunk = predictions_df[predictions_df.is_matching_chunk == False]\n",
    "\n",
    "    matching = predictions_df[predictions_df.is_matching_chunk]\n",
    "\n",
    "    non_na_ix = ((pd.isna(matching['count']) == False) & (matching['count'] != 0))\n",
    "\n",
    "    nonna = matching[non_na_ix]\n",
    "\n",
    "    print(f\"\"\"\n",
    "    Accuracy: {predictions_df['correct'].mean():.2f}\n",
    "    % FTS chose a chunk w/ annotated information: {predictions_df.is_matching_chunk.mean():.2f}\n",
    "    %  null when wrong chunk: {pd.isna(wrong_chunk['count']).mean():.2f}\n",
    "    Accuracy for cases when correct chunk was given to LLM: {matching['correct'].mean():.2f}\n",
    "    % LLM reported a non-na value when correct chunk was given: {non_na_ix.mean():.2f}\n",
    "    Accuracy for non-NA values w/ correct chunk given: {nonna['correct'].mean():.2f}\n",
    "    Accuracy within 10%: {(nonna.apply(lambda x: is_within_percentage(x['count'], x['annot_count'], 10), axis=1)).mean():.2f}\n",
    "    Accuracy within 20%: {(nonna.apply(lambda x: is_within_percentage(x['count'], x['annot_count'], 20), axis=1)).mean():.2f}\n",
    "    Accuracy within 30%: {(nonna.apply(lambda x: is_within_percentage(x['count'], x['annot_count'], 30), axis=1)).mean():.2f}\"\"\")\n",
    "\n",
    "    return predictions_df, nonna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3a0174b2-13b3-4195-aaf5-4014dc6cc249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Accuracy: 0.72\n",
      "    % FTS chose a chunk w/ annotated information: 0.91\n",
      "    %  null when wrong chunk: 0.17\n",
      "    Accuracy for cases when correct chunk was given to LLM: 0.79\n",
      "    % LLM reported a non-na value when correct chunk was given: 1.00\n",
      "    Accuracy for non-NA values w/ correct chunk given: 0.79\n",
      "    Accuracy within 10%: 0.86\n",
      "    Accuracy within 20%: 0.97\n",
      "    Accuracy within 30%: 0.98\n"
     ]
    }
   ],
   "source": [
    "full_text_demo, ft_nonna  = _print_evaluation(full_text_demo, single_group)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1ecee8-4b84-488f-b3a2-63c208f85a55",
   "metadata": {},
   "source": [
    "#### Summary\n",
    "\n",
    "When the correct chunk is given the GPT-3.5, it can extract a sample size value (although typically not final N), most of the time, with relatively few gross errors.\n",
    "\n",
    "However, when given the incorrect chunk, it will often not give `null` values when it should"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8d9095-5b36-4384-81ab-9c8480d8bcc7",
   "metadata": {},
   "source": [
    "#### Incorrect responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "12bedafb-0c0e-4e41-9eb9-73d5ab85cc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect = ft_nonna[ft_nonna['correct'] == False]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20c1854-2cd7-4648-bc81-1f3ed8f38e9f",
   "metadata": {},
   "source": [
    "- Majority are only off by a few, due to complex exclusion crtiera\n",
    "- Attempting to change the prompt to identify # of excluded subjects actually makes accuracy go down, and n deviates further from either final N or total N (and substracting the two numbers doesn't help)\n",
    "- In one case, the annotation is actually incorrect. (1/10)\n",
    "- Sometimes models  confused other info for demographic information (i.e. ROIs).\n",
    "  It seems as if the models are good at putting `n/a` for these section, but sometimes (in a non stable manner), fail"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a90b785-0895-4cd4-bc64-df3bf75ef77c",
   "metadata": {},
   "source": [
    "## GPT-4 Full Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "247a0399-b0e5-4e31-8577-7f78d75e6018",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 69/69 [03:17<00:00,  2.86s/it]\n"
     ]
    }
   ],
   "source": [
    "full_text_gpt4 = extract_sample_size_full_text(\n",
    "    single_group_embeddings_body, single_group,\n",
    "    'How many participants were recruited for this study?',\n",
    "    ZERO_SHOT_SAMPLE_SIZE_FUNCTION,\n",
    "    model_name='gpt-4',\n",
    "    num_workers=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "92f3e957-a619-454d-ba54-f8880b3a4a03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Accuracy: 0.86\n",
      "    % FTS chose a chunk w/ annotated information: 0.91\n",
      "    %  null when wrong chunk: 0.83\n",
      "    Accuracy for cases when correct chunk was given to LLM: 0.92\n",
      "    % LLM reported a non-na value when correct chunk was given: 1.00\n",
      "    Accuracy for non-NA values w/ correct chunk given: 0.92\n",
      "    Accuracy within 10%: 0.94\n",
      "    Accuracy within 20%: 0.98\n",
      "    Accuracy within 30%: 0.98\n"
     ]
    }
   ],
   "source": [
    "full_text_gpt4, ft_gpt4_nonna  = _print_evaluation(full_text_gpt4, single_group)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96bcd76-1370-408c-bdf8-6578baa30df8",
   "metadata": {},
   "source": [
    "GPT-4 is slightly more accurate, but more importantly, is less likely to hallucinate or get the wrong answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bc4cfecf-46f6-43be-8dc3-adb3672d6363",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(full_text_gpt4, open('data/full_text_gpt4_single_group.pkl', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
