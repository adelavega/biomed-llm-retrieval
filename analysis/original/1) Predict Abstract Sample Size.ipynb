{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "614587ee",
   "metadata": {},
   "source": [
    "# Prototype Sample Size extraction using GPT\n",
    "\n",
    "Goal: Test prompt engineering on the easiest use case: single "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4a04a86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from labelrepo.projects.participant_demographics import (\n",
    "    get_participant_demographics,\n",
    ")\n",
    "\n",
    "subgroups = get_participant_demographics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eb79e014",
   "metadata": {},
   "outputs": [],
   "source": [
    "abstracts = pd.read_csv('data/abstracts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5e751e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "jerome_pd = subgroups[(subgroups.project_name == 'participant_demographics') & (subgroups.annotator_name == 'Jerome_Dockes')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "93b67acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = jerome_pd.groupby('pmcid').count().reset_index()\n",
    "single_group_pmcids = counts[counts['count'] == 1].pmcid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c972de18",
   "metadata": {},
   "source": [
    "### Single group with Sample Size in Abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ccb83131",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_group = jerome_pd[jerome_pd.pmcid.isin(single_group_pmcids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6d3fb521",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_group = pd.merge(single_group, abstracts[abstracts.pmcid.isin(single_group.pmcid)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "10976021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heuristic for finding in abstract studies\n",
    "# Using fixed list below after manual checking\n",
    "# single_group['in_abstract'] = \\\n",
    "#  single_group.apply(lambda x: (re.search(f\"\\D{x['count']}\", x.abstract) != None), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a43feded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual list\n",
    "not_in_abstract = [5548834, 4029023, 4318429, 5324609, 8752963, 5218407, 3147157, 2775905, 6344389, 8837589, 7430162, 7563756, 7156375, 4330553, 6989437, 6328158, 3409150, 3775427, 3483694, 6787094, 6528067, 3869649, 3183226, 6868994, 7002496, 6492297, 3780305]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a49603f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_group['in_abstract'] = single_group.pmcid.isin(not_in_abstract) == False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06692aee",
   "metadata": {},
   "source": [
    "## Extract simple sample size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1ba76eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from templates import ZERO_SHOT_SAMPLE_SIZE_FUNCTION\n",
    "from extract import extract_from_multiple\n",
    "\n",
    "openai.api_key = open('/home/zorro/.keys/open_ai.key').read().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7126dabb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 75/75 [00:45<00:00,  1.64it/s]\n"
     ]
    }
   ],
   "source": [
    "predictions = extract_from_multiple(single_group.abstract.to_list(), \n",
    "                                    **ZERO_SHOT_SAMPLE_SIZE_FUNCTION, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9211293a-93bb-434a-9f49-825e0670b21c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      29.0\n",
       "1      21.0\n",
       "2       NaN\n",
       "3       NaN\n",
       "4     161.0\n",
       "      ...  \n",
       "70     12.0\n",
       "71      NaN\n",
       "72     33.0\n",
       "73      NaN\n",
       "74     27.0\n",
       "Name: count, Length: 75, dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions['count'].astype('int', errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "94a5584e-dfe4-4cab-9ad1-1209488018fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      29.0\n",
       "1      21.0\n",
       "2      10.0\n",
       "3      18.0\n",
       "4     173.0\n",
       "      ...  \n",
       "70     12.0\n",
       "71     20.0\n",
       "72     33.0\n",
       "73    820.0\n",
       "74     26.0\n",
       "Name: count, Length: 75, dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_group['count'].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "58a91f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize values\n",
    "predictions['pmcid'] = single_group['pmcid']\n",
    "single_group['count'] = single_group['count'].astype('float')\n",
    "\n",
    "predictions['correct'] = single_group['count'] == predictions['count']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312a83e0",
   "metadata": {},
   "source": [
    "### Only look at those with sample size in abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1bb7569b",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_abstract_predictions = predictions[single_group['in_abstract']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "124b1cd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8333333333333334"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Percentage correct\n",
    "in_abstract_predictions['correct'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6d468143",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>pmcid</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>161.0</td>\n",
       "      <td>9308181</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>149.0</td>\n",
       "      <td>4115625</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>41.0</td>\n",
       "      <td>2144768</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>69.0</td>\n",
       "      <td>5460048</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.0</td>\n",
       "      <td>8978988</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3182403</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>79.0</td>\n",
       "      <td>6678781</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>27.0</td>\n",
       "      <td>6509414</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    count    pmcid  correct\n",
       "4   161.0  9308181    False\n",
       "10  149.0  4115625    False\n",
       "12   41.0  2144768    False\n",
       "14   69.0  5460048    False\n",
       "26    0.0  8978988    False\n",
       "41    NaN  3182403    False\n",
       "56   79.0  6678781    False\n",
       "74   27.0  6509414    False"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Incorrect predictions\n",
    "in_abstract_predictions[in_abstract_predictions['correct'] == False]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b316395d",
   "metadata": {},
   "source": [
    "Notes: First error is due to pulling out sample size for behavioral task, not fMRI task. \n",
    "\n",
    "Second error is due to study being a single subject study."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ad336a",
   "metadata": {},
   "source": [
    "### Any hallucinations?\n",
    "\n",
    "In all these cases where the information is not in the abstract, the model should have predicted either null, or 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "26613d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_abstract_predictions = predictions[single_group['in_abstract'] == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d38aff08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7777777777777778"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicted `n/a` or got correct answer (i.e. misclassified as not having info in abstract)\n",
    "(pd.isna(no_abstract_predictions['count'])).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "72127b39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>pmcid</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5218407</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>8837589</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0</td>\n",
       "      <td>7430162</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5548834</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3483694</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3869649</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    count    pmcid  correct\n",
       "7     0.0  5218407    False\n",
       "18    0.0  8837589    False\n",
       "19    0.0  7430162    False\n",
       "40    0.0  5548834    False\n",
       "43    0.0  3483694    False\n",
       "52    0.0  3869649    False"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Studies where the model was wrong, and made a prediction\n",
    "no_abstract_predictions[(pd.isna(no_abstract_predictions['count']) == False) & (no_abstract_predictions['correct'] == False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a35fde",
   "metadata": {},
   "source": [
    "Overall notes: \n",
    "\n",
    "Errors:\n",
    "- 2 error due to discrepancy between methods and abstract count (final n vs starting n)\n",
    "- 1 n/a should be = 1\n",
    "- 1 was for behavioral count, not fMRI count\n",
    "\n",
    "False positives:\n",
    "- Age was extracted instead of sample size (fixed after improving prompt)\n",
    "- Returns 0 occasional instead of `n/a` (could be fixed in serialization). \n",
    "\n",
    "\n",
    "Excluding abstract/full-text discrepancies, error rate is 2/75"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
